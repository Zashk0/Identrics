[
{"title": "African universities are failing to prepare tech graduates for jobs in AI", "url": "https://restofworld.org/2024/ai-skills-training-africa/", "body": "After she graduated with a computer science degree from a state university in Nigeria late last year, Oyinda Olatunji was confident she\u2019d land a job with a local data science company by March. She had been through four rounds of interviews and thought the company would soon make her an offer. The company, however, decided to go with another candidate who had experience working on artificial intelligence. Olatunji had studied topics like data science and machine learning in college, but the course did not include any practical, real-world examples of how AI works. \u201cA data mining course that I did at university was all theory and I just don\u2019t have the right skills that recruitment companies look for,\u201d Olatunji told  . \u201cAs a result, job hunting has grown increasingly difficult.\u201d The 23-year-old said she has missed out on several other job opportunities due to a lack of practical experience in new technologies. Several other African tech graduates have faced similar challenges. More than   offer courses related to AI, including data science and machine learning. But recruitment consultants and academics told   that graduates from these courses are largely unemployable because the programs are not up-to-date with the industry\u2019s requirements. Several startups have stepped up to bridge this gap: They give young African tech graduates practical experience in AI by organizing projects and competitions where they can win cash prizes. These companies, including Zindi in South Africa,   and ChipLab in Nigeria, and ALX in Kenya, have helped thousands of students find jobs. \u201cAfrica\u2019s higher learning institutions have struggled to design curricula that align with the ever-evolving technology landscape, making it difficult for graduates to have the right AI skills,\u201d Abdul Moosa, chief technology officer at cybersecurity firm Cyberport Africa, told  . \u201cPrivate AI startups have emerged to assist graduates in acquiring relevant, practical, tailor-made AI skills and are collaborating with companies to provide internships. Those with such skills have huge success [in the job market].\u201d In the first two months of 2024, over 100,000 students enrolled in programs by ALX, a Kenya-based e-learning platform that offers courses related to data science and software engineering. The company, founded in 2015, started offering AI courses in 2018. Nearly 85% of South African students who took ALX\u2019s courses have found relevant jobs, Bavesh Sooka, the company\u2019s general manager in South Africa, told  . Zindi, a 6-year-old company, has seen nearly 73,000 data scientists use its platform, where it hosts hackathons and boot camps to train graduates and match them with potential employers, CEO Celina Lee told  . Zindi is backed by investors like AI firm   and investment firm Founders Factory Africa \u2014 it has helped over 100 engineers find jobs with Microsoft, Google, and Meta. \u201cWe came up with a model to challenge the notion that data-related solutions could only be found outside of Africa,\u201d Lee said. \u201cThe idea was to develop African talent so that the continent could solve data-related problems without having to look outside of Africa for solutions.\u201d Lawrence Moruye, who has a degree in mathematical sciences from Senegal, signed up for Zindi in September 2018. He wanted to learn programming skills that his school did not teach. Participating in hackathons on Zindi helped him get there. \u201cThe hackathons on Zindi taught me how to apply theory to solving real data-related problems and to find solutions \u2014 something that we never learned at varsity,\u201d Moruye told  . His experience earned him scholarships from Meta and Google to pursue a master\u2019s degree in machine learning. He now works as a data scientist at African e-commerce major Jumia. \"Africa is not prepared to reach its full AI potential because we do not have enough talent.\" The training provided by startups like Zindi is critical at a time when several African countries are dealing with high levels of unemployment, according to Abdul-Khaaliq Mohammed, an engineering professor at the University of the Witwatersrand in South Africa. \u201cEven after finishing a data science degree, graduates are finding that they are not experts in machine learning and AI, and for this, they require training and upskilling,\u201d Mohammed told  . \u201cNew players in AI and machine learning education are quicker to respond to the new trends, and by upskilling graduates, they increase their chances of being employed in the face of an unemployment crisis.\u201d The South African Ministry of Higher Education, Science, and Innovation, which is responsible for overseeing the quality of university education in the country, did not respond to  \u2019s request for comment. There is an acute shortage of AI-related talent in Africa, and governments across the continent need to step in to find a solution, according to Pipeloluwa Olayiwola, an engineering professor at Obafemi Awolowo University in Nigeria. \u201cAfrica is not prepared to reach its full AI potential because we do not have enough talent,\u201d Olayiwola told  . The few startups available may not have what it takes to train enough professionals, he said. \u201cThe best way is for African governments to invest in university AI programs. This, coupled with private startups, will help build an adequate number of AI professionals.\u201d ", "pub_datetime": "2024-04-29", "author": "Kimberly Mutandiro", "images": [], "ner": {"Person": [], "Organization": [], "Location": []}},
{"title": "AI companies are making millions producing election content in India", "url": "https://restofworld.org/2024/india-elections-ai-content/", "body": "Divyendra Singh Jadoun has a catalog of videos, audio, and images on his computer that he promptly presents each time someone asks him about his work. In one of the videos, an Indian politician can be seen talking in multiple Indian languages about the various projects undertaken by his government. In an audio recording, a political party representative can be heard calling a voter to inquire about the problems they face in their locality and seeking suggestions to address them. Some of these visuals and audio clips are so realistic that a layperson would never guess they \u2014 along with the other content in Jadaoun\u2019s catalog \u2014 have been created using artificial intelligence. Jadoun is the founder of Polymath Solution, a synthetic media company that started creating AI content for politicians in November last year. In just six months, the nine-member company \u2014 run out of an office in the small western Indian town of Pushkar \u2014 has worked on election campaigns for several major political parties, including the ruling Bharatiya Janata Party (BJP) and the leading opposition party Indian National Congress. With his content catalog, Jadoun has secured half a dozen political campaigning deals. The company expects to generate $241,000 in revenue during the six-week-long elections. It\u2019s not a tough target. AI content makers like Polymath are sought after by national and regional politicians in India amid what is being touted as the  . Four AI content agencies told   they are seeing more demand than they can manage, with political parties in the country projected to spend over $50 million on AI-generated campaign material this year. Even as they look to maximize their earnings, however, the AI content companies are filtering out \u201cunethical\u201d requests for fake content that could propagate misinformation. \u201cI can\u2019t work with 10 parties parallelly; I don\u2019t have the bandwidth for that,\u201d Senthil Nayagam, founder of AI media tech firm Muonium, based in the southern state of Tamil Nadu, told  . His company works only with political parties it can \u201ctrust and can vouch for,\u201d he said. India\u2019s general elections, where Prime Minister Narendra Modi is up for a third term, are being held in seven phases. The first phase concluded on April 19, and the last phase is scheduled for June 1. Nayagam started taking on political assignments in January. His first prominent project was with Tamil Nadu\u2019s ruling Dravida Munnetra Kazhagam (DMK) party. Nayagam\u2019s team created an AI video of the party\u2019s deceased iconic leader, M Karunanidhi,   the state administration. Just three months on, Nayagam is so swamped with contracts for political AI content that he has hired external studios, photographers, sound engineers, and editors to keep up with deadlines. \u201cWe have hired people who have previously worked in [the film] industry in VFX [or] CGI \u2026 for high-quality output and fast delivery,\u201d said Nayagam, who has worked with several regional parties. If a client\u2019s project requires a larger workforce, he brings in people with experience in audio, video, and visual effects. Muonium is working on campaigns for close to 10 politicians, and has earned hundreds of thousands of dollars, Nayagam said. He declined to disclose the exact numbers. \u201cEach candidate is willing to spend over a million rupees [$12,000] on using AI technology for their election campaigning,\u201d he said. The company had charged over $12,000 for the Karunanidhi video. Some of the most popular AI content during election campaigning this year includes personalized videos that can be circulated on WhatsApp, 3D holograms that can be viewed by scanning a QR code, and deepfake videos of politicians that are posted on social media platforms. Avantari Technologies, an AI content agency based in the southern city of Hyderabad, receives requests for politicians\u2019 deepfake videos on a near-daily basis. CEO Bhairav Shankar told   the company declines such requests. Avantari was among the first to use digital tools in election campaigns. In 2012, during the Gujarat state elections, the company developed 3D holograms for then-Chief Minister Modi. \u201cWe work in the political space and [to] successfully work in the political space, it\u2019s very important to maintain our reputation,\u201d Shankar said. Without disclosing a name, he said the company has chosen to focus solely on one political party to maintain project integrity. \u201cWe would not want to besmirch it by \u2026 doing anything that is unethical. We\u2019re happy to do everything that we can to make our party win, but not cross the line.\u201d Political parties are willing to invest millions in a technology-driven campaign if it achieves their objectives, Shankar said. If a party is trying to run a campaign which could \u201ctouch almost every person in [their] state,\u201d even a fee of $10 million \u201cbecomes a very average figure\u201d to pay, he said. But despite AI companies like Avantari turning down requests for political deepfakes,\u00a0several such videos have circulated on the Indian internet this election season. Some recent viral deepfakes showed prominent Bollywood celebrities Aamir Khan and Ranveer Singh  . Companies told   they often encounter a conflict of interest  \u2014 when two opposing parties approach them at once. If a deal is finalized, an AI agency usually doesn\u2019t work with opposition parties in the same state or area, Jadoun said. \u201cBut nobody has ever asked us also if you work with opposition candidates.\u201d There\u2019s no upper limit to what an agency can charge for its services, Sagar Vishnoi, a Delhi-based political strategist, told  . \u201cIndividual party expenditures vary, with major parties potentially earmarking over a million dollars for AI initiatives,\u201d he said. \u201cBut an average Lok Sabha [the lower house of Indian Parliament] candidate might allocate approximately $80,000 to $90,000, depending on financial capability and recognition of the effectiveness of innovative campaign strategies.\u201d Polymath has a tiered pricing structure based on project complexity. When it comes to personalized video messaging, the company charges 60,000 rupees ($720) for voice cloning, 1 lakh rupees ($1,200) for digital avatar creation, and up to 2 lakh rupees ($2,400) for WhatsApp integration. Meanwhile, Avantari charges 10 lakh rupees ($12,000) for voice cloning, and up to 25 rupees (30 cents) per video message. \u201cFor WhatsApp integration, we make a separate application and run a call center for bulk messaging. This costs 30 rupees [36 cents] per WhatsApp message,\u201d Shankar said. Payments are usually made in three installments. \u201cAfter signing the NDA, we receive the first installment of [30%],\u201d Varun Bisaria, who manages clients for Polymath, told  . The other two installments are paid after the content is finalized and the project completed.\u00a0 Before finalizing a deal, all the four AI agencies make their clients sign nondisclosure agreements, outlining ethical guidelines and the details, duration, and pricing of the content created. The agreement includes the payment schedule for the project. Once Polymath has received data from the client, it starts training AI for voice modulation, pronunciation of names in different languages and dialects, and lip-syncing, Jadoun said. The videos are then tailored to the client\u2019s language preference and distributed over WhatsApp using algorithms to personalize the outreach to each recipient. Jadoun has begun outsourcing work to freelance developers he finds on Instagram and LinkedIn. \u201cOur workload is increasing, so we\u2019ve started expanding our in-house team as well,\u201d he said. At Avantari, the company\u2019s AI engineers develop and deploy the software. The most important members in the team, according to Shankar, are the quality controllers, who check the quality of the content before it reaches voters. The demand for AI material is higher in some states than others, depending on the local politicians\u2019 campaign budgets, Diggaj Mogra, director of Jarvis Consulting, a Mumbai-based political consulting firm, told  . Mogra is   during this election. Election campaign spending in the southern states of Andhra Pradesh, Telangana, and Karnataka is \u201chefty,\u201d which means there is a higher investment in tech-related tools, according to Mogra. In contrast, he said, the budgets are much smaller in Bihar. \u201cWhile only a handful of parties embrace technology fully,\u201d some are willing to invest up to 20% of their total campaign budget on communication tools like WhatsApp and an AI-enabled interactive voice response system, he said. As parties pump more money into AI campaign materials, there are risks that the technology might be misused, Mogra said. He said he knows of some politicians who are planning to launch defamatory attacks using AI-generated content. Deepfake experts have previously told   that AI   when politicians want to distance themselves from unflattering content. AI is still in its infancy, according to Mogra. It does not have the same impact as on-the-ground campaigning because it currently plays only \u201ca supporting part,\u201d he said. \u201cIn the next elections of 2029, AI will be a big thing, but right now, it is only in the experimental phase.\u201d", "pub_datetime": "2024-04-30", "author": "Fahad Shah", "images": [], "ner": {"Person": [], "Organization": [], "Location": []}},
{"title": "Writers and publishers in Singapore reject a government plan to train AI on their work", "url": "https://restofworld.org/2024/singapore-writers-reject-ai-training/", "body": "When the Singaporean government asked local writers if they would agree to having their work used to train a large language model, it probably did not expect the country\u2019s tiny literary community to react so fiercely. An email sent late in March said that the National Multimodal LLM Programme (NMLP) aimed to address the bias of existing LLMs that have \u201cdisproportionately large influences\u201d from Western societies. Singapore\u2019s own LLM, trained on material produced locally, would have more accurate references to the nation\u2019s history, colloquialisms, and culture and train on widely spoken languages, such as Malay, Mandarin, and Tamil, it said. However, writers such as Gwee Li Sui, one of the city\u2019s best-known literary figures, are not convinced.\u00a0 \u201cThe stages of planning [for the LLM] before writers are even considered as worth consulting do not inspire confidence that my interest will be a priority,\u201d Gwee, author of more than a dozen books, told  . There is also little clarity on how the works would be protected from being used \u201cfor purposes other than what is now claimed as public service towards cultural representation,\u201d he said. The email initially gave respondents 10 days to respond to  . But it had few details on compensation or copyright protection. So Gwee declined to let the LLM train on his works, including the first book written entirely in Singlish \u2014 a creole language that is a blend of Singaporean slang and English and is widely spoken in the country. Gwee is one of several in the city-state\u2019s tiny literary community pushing back against the government\u2019s efforts to incorporate their works into the NMLP. The S$70 million ($52 million) project, launched last December, is touted as Southeast Asia\u2019s first regional LLM and is part of Singapore\u2019s ambitious plan to become a global leader in artificial intelligence by 2030.\u00a0 The disgruntled Singaporean writers are part of a worldwide growing resistance\u00a0to the use of published works to train AI technologies. Last year, U.S. comedian Sarah Silverman joined a class-action lawsuit with other authors against OpenAI and one against Meta, accusing the companies of copyright infringement for using protected work to train AI programs. In  , more than a dozen authors, including John Grisham and George R.R. Martin, have accused OpenAI of similarly infringing on their copyrights to train the popular ChatGPT chatbot. Publishers, including  , have also   and Microsoft for the same reason. \u201cMost LLM developers have taken the stance that web-scraped data is fair game to train on.\u201d Actions such as these are rare in Asia. Earlier this year, a Chinese court found that images generated by an AI service   of a science fiction character created by a Japanese studio. But as countries, including India, Indonesia,  , and Vietnam, develop their own multilingual LLMs, there is little clarity on what material is being used for training, what copyright protections authors have, and what \u2014 if any \u2014 compensation authors will receive. Singaporean   the NMLP will be trained in 11 regional languages to capture Southeast Asia\u2019s \u201cunique linguistic characteristics and multilingual environment.\u201d Building on the existing   (South-East Asian Languages In One Network) family of LLMs, it will eventually form the basis for text-to-speech and text-to-image generative programs that can be used in translation and customer-service chatbots and other applications. The email sent on behalf of Singapore\u2019s Infocomm Media Development Authority (IMDA), the lead government agency driving the LLM project, said that all data contributed would be used solely for \u201cresearch purposes.\u201d It said it recognized that the development of AI and its impact on writers was a \u201chot-button issue\u201d but made no mention of compensation.\u00a0 Despite the writers\u2019 criticism, \u201cthis level of proactive consent-seeking is quite rare,\u201d according to Nuurrianti Jalli, an assistant professor at Oklahoma State University who has studied multilingual LLMs. \u201cMost LLM developers have taken the stance that web-scraped data is fair game to train on, without getting permission from individual copyright holders,\u201d Jalli told  . \u201cSo the Singapore government\u2019s approach stands out as unusually considerate of writers\u2019 rights. But writers understandably also want to know specifics.\u201d In response to queries, the IMDA referred   to its earlier statement to local media, where a spokesperson said the survey was \u201ca research effort to advance understanding\u201d of the project. \u201cThe intent therefore was to consult the broader community on how we might approach this,\u201d the agency had said. Singapore authorities have historically had an uneasy relationship with the arts community, banning or censoring various works over the years for contravening official guidelines on race, religion, and politics. New laws have also cracked down on  , while government grants prioritize creative works that do not \u201c \u201d of institutions.\u00a0 Now, Singaporean writers are fearful of AI misusing their work with government sanction. \u201cThe work of authors, translators, and publishers in Singapore and the rest of Southeast Asia ought to be treated with due respect,\u201d New York\u2013based literary organization Singapore Unbound  in response to the IMDA survey, which it did not receive  \u201cIt is not merely data for the machines, but the living tissue of our societies,\u201d it said. There are also \u201clots of gray areas\u201d when it comes to copyright, and the legal status of training LLMs on copyrighted content is still uncertain, Peter Schoppert, director of National University of Singapore Press, an academic publisher, told  . \u201cIt is not merely data for the machines, but the living tissue of our societies.\u201d \u201cNeither Singapore\u2019s text-and-data-mining exception nor the fair-use provisions in its   would allow the training of LLMs that can then generate works without consent, credit, and compensation from copyright holders,\u201d he said, adding that this is an interpretation that is yet to be tested in the courts. Still, countries building multilingual LLMs are contending with a paucity of high-quality data to train on, so Singapore stands to gain by getting writers on its side, said Jalli. \u201cIf key opinion leaders and writers withhold their work, the LLMs may have to rely more on lower-quality web-scraped content, which could limit their coherence and factual reliability,\u201d she said. \u201cSo getting buy-in from the local writing and creative community is important for building public trust in the technology.\u201d While some negotiations with the government have taken place, few Singaporean writers and publishers think they will make much headway.\u00a0 \u201cThe government is a juggernaut compared to us. If they want to ride roughshod over us, there is very little we can do,\u201d said a member of the publishing industry, who asked not to be named, as they were still lobbying authorities on the matter. Award-winning author Dave Chua is also resigned to the project moving ahead regardless of their sentiments, with compensation hard to come by. \u201cI think they will just try to use works that are in the public domain and when authors give permission for their work to be used without compensation,\u201d Chua told   He said yes to having his material used in the LLM training, as he is \u201ccurious\u201d to see what such an LLM would produce, he said. Singapore\u2019s founding father and former prime minister, Lee Kuan Yew, famously said that \u201cpoetry is a luxury we cannot afford,\u201d and this survivalist mindset has often dictated the government\u2019s attitude towards the arts. \u201cUltimately, our governance is a very pragmatic one,\u201d Ng Kah Gay, editor at independent publisher Ethos Books, told  . \u201cFor us to hope that the government will see our value, we also have to show our relevance to the life and culture of our current society.\u201d", "pub_datetime": "2024-05-08", "author": "Nicholas Yong", "images": [], "ner": {"Person": [], "Organization": [], "Location": []}},
{"title": "OpenAI is making a risky bet on live translation", "url": "https://restofworld.org/2024/exporter-openai-translation-gpt4o/", "body": "On Monday, OpenAI held its \u201cspring update\u201d product reveal, generating the kind of excitement that\u2019s usually reserved for Apple or Tesla launches. The hope was that the Sam Altman-helmed AI powerhouse would reveal its next-generation model, GPT-5 \u2014 but it was not to be. Instead, we got a smaller update   that makes the current model faster and easier to access.\u00a0 Among other things, that means GPT-4o is much better at extracting data from pictures, audio, and video \u2014 but the star of the show is voice control, which lets you talk to GPT-4o the way you\u2019d talk to Apple\u2019s Siri or Amazon\u2019s Alexa. GPT-4o goes beyond those assistants with more realistic vocal inflections and a level of emotional expressiveness that was drawing a lot of comparisons to the Scarlett Johansson-voiced AI assistant in 2013\u2019s  . Altman himself   the comparisons, although  . If OpenAI can build a universal translator, it will be a company-defining product. But to my eyes, the most interesting moment was  , in which chief technology officer Mira Murati spoke to GPT-4o in Italian, and the model provided a real-time summary of what she was saying, translated into English. It was a stunning demo; this kind of real-time   translation has been a holy grail in tech for a long time, and the appeal isn\u2019t hard to grasp. Google even  . But that product was bundled into a set of smart glasses and never quite materialized. If OpenAI can build a universal translator \u2014 and make it cheap, reliable, and freely available \u2014 it will be a company-defining product. The question is whether OpenAI can actually deliver the universal translator we saw on stage. As the name suggests, large language models are trained by analyzing a large data set of content in a particular language. That\u2019s easy enough in English, the dominant language of the internet. But a universal translator needs to be proficient in every language, and finding training data in other languages is  . Even popular languages like Spanish are \u2014 compared to the number of people who speak the language \u2014 relatively  . If national writers\u2019 groups start to refuse access to their work,  , the problem could get even worse. We\u2019ve already seen ChatGPT struggle with global languages. When   tested ChatGPT in September, it   in low-resource languages like Tamil, Bengali, and Kurdish. As of March 2023, OpenAI\u2019s own benchmarks showed   with GPT-4, with test scores dropping noticeably as it moves into more obscure languages. That bias can do real harm, particularly when machine translations end up in use in high-stakes use cases like   or  . The models that handle low-resource languages the best,  , tend to take a language-specific approach \u2014 a different approach from the multi-language models built by OpenAI. To OpenAI\u2019s credit, they seem to be aware of the problem and doing their best to fix it. Translation is a simpler task than doing calculations in a foreign language, and in my own informal testing, GPT-4o did a pretty good job translating and summarizing  . But   show that even the most advanced models make significantly more mistakes when translating from Chinese to English than the other way around. And the scarcity of training data means foreign-language skills may improve more slowly than functions like data extraction or summarization. Before Monday, those language issues weren\u2019t a particularly urgent issue for OpenAI. But now the company is actively framing GPT-4o as a translation service, which raises real questions about how it\u2019ll hold up in widespread use. It also comes at an unusually high-stakes time for OpenAI: Within 24 hours of the demo, co-founder Ilya Sutskever   and Google released   (sans translation features). Monday\u2019s demo was stunning, but it\u2019s one OpenAI may regret if the technology can\u2019t deliver. This essay was originally published in our Exporter newsletter. You can subscribe  .", "pub_datetime": "2024-05-16", "author": "Russell Brandom", "images": [], "ner": {"Person": [], "Organization": [], "Location": []}},
{"title": "Indian politicians are bringing the dead on the campaign trail, with help from AI", "url": "https://restofworld.org/2024/dead-relatives-ai-deepfake-india/", "body": "Last month, movie star-turned-politician Vijay Vasanth was campaigning in an open jeep under an unforgiving sun in the sleepy fishing town of Kanniyakumari, the southernmost tip of the Indian mainland. He periodically waved to the fisherfolk lined up on either side of the street. Sometimes, as the vehicle slowed down, kids clambered up the bonnet and tugged at his sleeves for sweets that he kept in a container up front. It\u2019s classic electoral campaigning. And it\u2019s hard work.\u00a0 But in a hyper-wired world, it\u2019s no longer considered enough.\u00a0 Vasanth\u2019s campaign manager, a young man in his 20s, pulled out his phone to show me a video in which a gentleman in a crisp white kurta and neatly folded scarf leans back against a tall chair. He is H. Vasanth Kumar \u2014 the candidate\u2019s father, a local businessman, and the previous parliamentary representative of this constituency. Except Kumar is no longer alive. He died from Covid-19 four years ago. Kumar, who began his career as a salesman before starting a successful consumer goods company, typically had billboards across Kanniyakumari plastered with images of him advertising his business. His son\u2019s campaign team wants to recreate the familiarity of those images. In the video, Kumar, speaking in Tamil, explains how \u201cthough I died, my soul is still with all of you.\u201d He goes on to extol the virtues of his son: \u201cI can assure you that my son, Vijay, will work for the betterment of Kanniyakumari and for the progress of your children.\u201d As elections in India get in full swing, the country\u2019s leading politicians and their brand gurus have gone all in on artificial intelligence to resurrect the past and manage the future. Digital rights activists have questioned the ethics of using a deceased politician\u2019s voice or form in elections. There\u2019s the question of rights \u2014 who owns their legacy? \u2014 but more importantly, there\u2019s a humanizing aspect to \u201csoft fakes,\u201d as they are called. No one wants to speak ill of the dead, especially in India, where we have been culturally shaped to only eulogize those no longer with us. In January this year,  , the patriarch of politics in the southern state of Tamil Nadu, first appeared in an AI video at a conference for his party\u2019s youth wing. In the clip, he wore the look for which he is best remembered: a luminous yellow scarf and oversized dark glasses. Even his head was tilted, just slightly to one side, to replicate a familiar stance from real life. Two days later, he made another appearance at the book launch of a colleague\u2019s memoirs. Karunanidhi died in 2018. \u201cThe idea is to enthuse party cadres,\u201d Salem Dharanidharan, a spokesperson for the Dravida Munnetra Kazhagam (DMK) \u2014 the party that Karunanidhi led till his death \u2014 told me. \u201cIt excites older voters among whom Kalaignar [\u201cMan of Letters,\u201d as Karunanidhi was popularly called] already has a following. It spreads his ideals among younger voters who have not seen enough of him. And it also has an entertainment factor \u2014 to recreate a popular leader who is dead.\u201d Across the world, countries are grappling with similar dilemmas. Americans, for instance, banned robocalls, or AI-generated voice calls. Fake robocalls, impersonating President Joe Biden\u2019s voice, were used to try and persuade citizens not to vote in the New Hampshire primaries. The cloning was most likely done using  , one of Silicon Valley\u2019s most successful startup stories. The company\u2019s technology was also used to generate AI videos of Imran Khan, the jailed former Pakistani prime minister. And it\u2019s open to all \u2014 no prior permissions are needed from the person being imitated. ElevenLabs separately categorizes cloning used for \u201cnon-commercial purposes,\u201d like politics and public debate. In the hurly-burly of the Indian election season, though, all this is entirely esoteric and academic. No one wants to speak ill of the dead, especially in India, where we have been culturally shaped to only eulogize those no longer with us. According to Dharanidharan, AI for politicians is a mere mechanism, much like the newspaper or printing press were back in the day. \u201cIn the 1920s, our party used newspapers as a medium to propagate ideology; in the late \u201940s up to the \u201980s, we used film and cinema; in the \u201990s, we used cable TV \u2014 and now it\u2019s AI.\u201d India\u2019s prime minister, Narendra Modi, has been an early user of an  , which translates his voice from Hindi to other languages in real time. Shashi Tharoor, a minister from the opposing Indian National Congress, conducted an interview with his  . And as AI goes mainstream, the first big quarrel between the ruling Bharatiya Janata Party and the Congress party has led to a police summons: Home Minister Amit Shah alleged that  , the Congress\u2019 recently elected chief minister in Telangana, used deepfake tech to alter a video that twisted Shah\u2019s views on affirmative action quotas. Not surprisingly, new businesses that boast about providing the ultimate   are suddenly much in demand.\u00a0 But as the lines between real and fake blur, manipulation is fast becoming a challenge \u2014 and it\u2019s far more dire than when misinformation used to be exchanged via text messages or WhatsApp forwards. Two of   had to deny that they had issued messages urging people to vote against the ruling party.\u00a0 Voters are now receiving calls from supposed local representatives who engage in a full-blown conversation about the most pressing issues in their area \u2014 except they   the call. The full impact of AI on voting choices may not be understood in this election cycle. But if effective public communication was once all about human connection and authenticity, generative AI seems to have turned that premise on its head.", "pub_datetime": "2024-05-06", "author": "Barkha Dutt", "images": [], "ner": {"Person": [], "Organization": [], "Location": []}}
][
{"title": "African universities are failing to prepare tech graduates for jobs in AI", "url": "https://restofworld.org/2024/ai-skills-training-africa/", "body": "After she graduated with a computer science degree from a state university in Nigeria late last year, Oyinda Olatunji was confident she\u2019d land a job with a local data science company by March. She had been through four rounds of interviews and thought the company would soon make her an offer. The company, however, decided to go with another candidate who had experience working on artificial intelligence. Olatunji had studied topics like data science and machine learning in college, but the course did not include any practical, real-world examples of how AI works. \u201cA data mining course that I did at university was all theory and I just don\u2019t have the right skills that recruitment companies look for,\u201d Olatunji told  . \u201cAs a result, job hunting has grown increasingly difficult.\u201d The 23-year-old said she has missed out on several other job opportunities due to a lack of practical experience in new technologies. Several other African tech graduates have faced similar challenges. More than   offer courses related to AI, including data science and machine learning. But recruitment consultants and academics told   that graduates from these courses are largely unemployable because the programs are not up-to-date with the industry\u2019s requirements. Several startups have stepped up to bridge this gap: They give young African tech graduates practical experience in AI by organizing projects and competitions where they can win cash prizes. These companies, including Zindi in South Africa,   and ChipLab in Nigeria, and ALX in Kenya, have helped thousands of students find jobs. \u201cAfrica\u2019s higher learning institutions have struggled to design curricula that align with the ever-evolving technology landscape, making it difficult for graduates to have the right AI skills,\u201d Abdul Moosa, chief technology officer at cybersecurity firm Cyberport Africa, told  . \u201cPrivate AI startups have emerged to assist graduates in acquiring relevant, practical, tailor-made AI skills and are collaborating with companies to provide internships. Those with such skills have huge success [in the job market].\u201d In the first two months of 2024, over 100,000 students enrolled in programs by ALX, a Kenya-based e-learning platform that offers courses related to data science and software engineering. The company, founded in 2015, started offering AI courses in 2018. Nearly 85% of South African students who took ALX\u2019s courses have found relevant jobs, Bavesh Sooka, the company\u2019s general manager in South Africa, told  . Zindi, a 6-year-old company, has seen nearly 73,000 data scientists use its platform, where it hosts hackathons and boot camps to train graduates and match them with potential employers, CEO Celina Lee told  . Zindi is backed by investors like AI firm   and investment firm Founders Factory Africa \u2014 it has helped over 100 engineers find jobs with Microsoft, Google, and Meta. \u201cWe came up with a model to challenge the notion that data-related solutions could only be found outside of Africa,\u201d Lee said. \u201cThe idea was to develop African talent so that the continent could solve data-related problems without having to look outside of Africa for solutions.\u201d Lawrence Moruye, who has a degree in mathematical sciences from Senegal, signed up for Zindi in September 2018. He wanted to learn programming skills that his school did not teach. Participating in hackathons on Zindi helped him get there. \u201cThe hackathons on Zindi taught me how to apply theory to solving real data-related problems and to find solutions \u2014 something that we never learned at varsity,\u201d Moruye told  . His experience earned him scholarships from Meta and Google to pursue a master\u2019s degree in machine learning. He now works as a data scientist at African e-commerce major Jumia. \"Africa is not prepared to reach its full AI potential because we do not have enough talent.\" The training provided by startups like Zindi is critical at a time when several African countries are dealing with high levels of unemployment, according to Abdul-Khaaliq Mohammed, an engineering professor at the University of the Witwatersrand in South Africa. \u201cEven after finishing a data science degree, graduates are finding that they are not experts in machine learning and AI, and for this, they require training and upskilling,\u201d Mohammed told  . \u201cNew players in AI and machine learning education are quicker to respond to the new trends, and by upskilling graduates, they increase their chances of being employed in the face of an unemployment crisis.\u201d The South African Ministry of Higher Education, Science, and Innovation, which is responsible for overseeing the quality of university education in the country, did not respond to  \u2019s request for comment. There is an acute shortage of AI-related talent in Africa, and governments across the continent need to step in to find a solution, according to Pipeloluwa Olayiwola, an engineering professor at Obafemi Awolowo University in Nigeria. \u201cAfrica is not prepared to reach its full AI potential because we do not have enough talent,\u201d Olayiwola told  . The few startups available may not have what it takes to train enough professionals, he said. \u201cThe best way is for African governments to invest in university AI programs. This, coupled with private startups, will help build an adequate number of AI professionals.\u201d ", "pub_datetime": "2024-04-29", "author": "Kimberly Mutandiro", "images": [], "ner": {"Person": [], "Organization": [], "Location": []}},
{"title": "OpenAI is making a risky bet on live translation", "url": "https://restofworld.org/2024/exporter-openai-translation-gpt4o/", "body": "On Monday, OpenAI held its \u201cspring update\u201d product reveal, generating the kind of excitement that\u2019s usually reserved for Apple or Tesla launches. The hope was that the Sam Altman-helmed AI powerhouse would reveal its next-generation model, GPT-5 \u2014 but it was not to be. Instead, we got a smaller update   that makes the current model faster and easier to access.\u00a0 Among other things, that means GPT-4o is much better at extracting data from pictures, audio, and video \u2014 but the star of the show is voice control, which lets you talk to GPT-4o the way you\u2019d talk to Apple\u2019s Siri or Amazon\u2019s Alexa. GPT-4o goes beyond those assistants with more realistic vocal inflections and a level of emotional expressiveness that was drawing a lot of comparisons to the Scarlett Johansson-voiced AI assistant in 2013\u2019s  . Altman himself   the comparisons, although  . If OpenAI can build a universal translator, it will be a company-defining product. But to my eyes, the most interesting moment was  , in which chief technology officer Mira Murati spoke to GPT-4o in Italian, and the model provided a real-time summary of what she was saying, translated into English. It was a stunning demo; this kind of real-time   translation has been a holy grail in tech for a long time, and the appeal isn\u2019t hard to grasp. Google even  . But that product was bundled into a set of smart glasses and never quite materialized. If OpenAI can build a universal translator \u2014 and make it cheap, reliable, and freely available \u2014 it will be a company-defining product. The question is whether OpenAI can actually deliver the universal translator we saw on stage. As the name suggests, large language models are trained by analyzing a large data set of content in a particular language. That\u2019s easy enough in English, the dominant language of the internet. But a universal translator needs to be proficient in every language, and finding training data in other languages is  . Even popular languages like Spanish are \u2014 compared to the number of people who speak the language \u2014 relatively  . If national writers\u2019 groups start to refuse access to their work,  , the problem could get even worse. We\u2019ve already seen ChatGPT struggle with global languages. When   tested ChatGPT in September, it   in low-resource languages like Tamil, Bengali, and Kurdish. As of March 2023, OpenAI\u2019s own benchmarks showed   with GPT-4, with test scores dropping noticeably as it moves into more obscure languages. That bias can do real harm, particularly when machine translations end up in use in high-stakes use cases like   or  . The models that handle low-resource languages the best,  , tend to take a language-specific approach \u2014 a different approach from the multi-language models built by OpenAI. To OpenAI\u2019s credit, they seem to be aware of the problem and doing their best to fix it. Translation is a simpler task than doing calculations in a foreign language, and in my own informal testing, GPT-4o did a pretty good job translating and summarizing  . But   show that even the most advanced models make significantly more mistakes when translating from Chinese to English than the other way around. And the scarcity of training data means foreign-language skills may improve more slowly than functions like data extraction or summarization. Before Monday, those language issues weren\u2019t a particularly urgent issue for OpenAI. But now the company is actively framing GPT-4o as a translation service, which raises real questions about how it\u2019ll hold up in widespread use. It also comes at an unusually high-stakes time for OpenAI: Within 24 hours of the demo, co-founder Ilya Sutskever   and Google released   (sans translation features). Monday\u2019s demo was stunning, but it\u2019s one OpenAI may regret if the technology can\u2019t deliver. This essay was originally published in our Exporter newsletter. You can subscribe  .", "pub_datetime": "2024-05-16", "author": "Russell Brandom", "images": [], "ner": {"Person": [], "Organization": [], "Location": []}},
{"title": "AI companies are making millions producing election content in India", "url": "https://restofworld.org/2024/india-elections-ai-content/", "body": "Divyendra Singh Jadoun has a catalog of videos, audio, and images on his computer that he promptly presents each time someone asks him about his work. In one of the videos, an Indian politician can be seen talking in multiple Indian languages about the various projects undertaken by his government. In an audio recording, a political party representative can be heard calling a voter to inquire about the problems they face in their locality and seeking suggestions to address them. Some of these visuals and audio clips are so realistic that a layperson would never guess they \u2014 along with the other content in Jadaoun\u2019s catalog \u2014 have been created using artificial intelligence. Jadoun is the founder of Polymath Solution, a synthetic media company that started creating AI content for politicians in November last year. In just six months, the nine-member company \u2014 run out of an office in the small western Indian town of Pushkar \u2014 has worked on election campaigns for several major political parties, including the ruling Bharatiya Janata Party (BJP) and the leading opposition party Indian National Congress. With his content catalog, Jadoun has secured half a dozen political campaigning deals. The company expects to generate $241,000 in revenue during the six-week-long elections. It\u2019s not a tough target. AI content makers like Polymath are sought after by national and regional politicians in India amid what is being touted as the  . Four AI content agencies told   they are seeing more demand than they can manage, with political parties in the country projected to spend over $50 million on AI-generated campaign material this year. Even as they look to maximize their earnings, however, the AI content companies are filtering out \u201cunethical\u201d requests for fake content that could propagate misinformation. \u201cI can\u2019t work with 10 parties parallelly; I don\u2019t have the bandwidth for that,\u201d Senthil Nayagam, founder of AI media tech firm Muonium, based in the southern state of Tamil Nadu, told  . His company works only with political parties it can \u201ctrust and can vouch for,\u201d he said. India\u2019s general elections, where Prime Minister Narendra Modi is up for a third term, are being held in seven phases. The first phase concluded on April 19, and the last phase is scheduled for June 1. Nayagam started taking on political assignments in January. His first prominent project was with Tamil Nadu\u2019s ruling Dravida Munnetra Kazhagam (DMK) party. Nayagam\u2019s team created an AI video of the party\u2019s deceased iconic leader, M Karunanidhi,   the state administration. Just three months on, Nayagam is so swamped with contracts for political AI content that he has hired external studios, photographers, sound engineers, and editors to keep up with deadlines. \u201cWe have hired people who have previously worked in [the film] industry in VFX [or] CGI \u2026 for high-quality output and fast delivery,\u201d said Nayagam, who has worked with several regional parties. If a client\u2019s project requires a larger workforce, he brings in people with experience in audio, video, and visual effects. Muonium is working on campaigns for close to 10 politicians, and has earned hundreds of thousands of dollars, Nayagam said. He declined to disclose the exact numbers. \u201cEach candidate is willing to spend over a million rupees [$12,000] on using AI technology for their election campaigning,\u201d he said. The company had charged over $12,000 for the Karunanidhi video. Some of the most popular AI content during election campaigning this year includes personalized videos that can be circulated on WhatsApp, 3D holograms that can be viewed by scanning a QR code, and deepfake videos of politicians that are posted on social media platforms. Avantari Technologies, an AI content agency based in the southern city of Hyderabad, receives requests for politicians\u2019 deepfake videos on a near-daily basis. CEO Bhairav Shankar told   the company declines such requests. Avantari was among the first to use digital tools in election campaigns. In 2012, during the Gujarat state elections, the company developed 3D holograms for then-Chief Minister Modi. \u201cWe work in the political space and [to] successfully work in the political space, it\u2019s very important to maintain our reputation,\u201d Shankar said. Without disclosing a name, he said the company has chosen to focus solely on one political party to maintain project integrity. \u201cWe would not want to besmirch it by \u2026 doing anything that is unethical. We\u2019re happy to do everything that we can to make our party win, but not cross the line.\u201d Political parties are willing to invest millions in a technology-driven campaign if it achieves their objectives, Shankar said. If a party is trying to run a campaign which could \u201ctouch almost every person in [their] state,\u201d even a fee of $10 million \u201cbecomes a very average figure\u201d to pay, he said. But despite AI companies like Avantari turning down requests for political deepfakes,\u00a0several such videos have circulated on the Indian internet this election season. Some recent viral deepfakes showed prominent Bollywood celebrities Aamir Khan and Ranveer Singh  . Companies told   they often encounter a conflict of interest  \u2014 when two opposing parties approach them at once. If a deal is finalized, an AI agency usually doesn\u2019t work with opposition parties in the same state or area, Jadoun said. \u201cBut nobody has ever asked us also if you work with opposition candidates.\u201d There\u2019s no upper limit to what an agency can charge for its services, Sagar Vishnoi, a Delhi-based political strategist, told  . \u201cIndividual party expenditures vary, with major parties potentially earmarking over a million dollars for AI initiatives,\u201d he said. \u201cBut an average Lok Sabha [the lower house of Indian Parliament] candidate might allocate approximately $80,000 to $90,000, depending on financial capability and recognition of the effectiveness of innovative campaign strategies.\u201d Polymath has a tiered pricing structure based on project complexity. When it comes to personalized video messaging, the company charges 60,000 rupees ($720) for voice cloning, 1 lakh rupees ($1,200) for digital avatar creation, and up to 2 lakh rupees ($2,400) for WhatsApp integration. Meanwhile, Avantari charges 10 lakh rupees ($12,000) for voice cloning, and up to 25 rupees (30 cents) per video message. \u201cFor WhatsApp integration, we make a separate application and run a call center for bulk messaging. This costs 30 rupees [36 cents] per WhatsApp message,\u201d Shankar said. Payments are usually made in three installments. \u201cAfter signing the NDA, we receive the first installment of [30%],\u201d Varun Bisaria, who manages clients for Polymath, told  . The other two installments are paid after the content is finalized and the project completed.\u00a0 Before finalizing a deal, all the four AI agencies make their clients sign nondisclosure agreements, outlining ethical guidelines and the details, duration, and pricing of the content created. The agreement includes the payment schedule for the project. Once Polymath has received data from the client, it starts training AI for voice modulation, pronunciation of names in different languages and dialects, and lip-syncing, Jadoun said. The videos are then tailored to the client\u2019s language preference and distributed over WhatsApp using algorithms to personalize the outreach to each recipient. Jadoun has begun outsourcing work to freelance developers he finds on Instagram and LinkedIn. \u201cOur workload is increasing, so we\u2019ve started expanding our in-house team as well,\u201d he said. At Avantari, the company\u2019s AI engineers develop and deploy the software. The most important members in the team, according to Shankar, are the quality controllers, who check the quality of the content before it reaches voters. The demand for AI material is higher in some states than others, depending on the local politicians\u2019 campaign budgets, Diggaj Mogra, director of Jarvis Consulting, a Mumbai-based political consulting firm, told  . Mogra is   during this election. Election campaign spending in the southern states of Andhra Pradesh, Telangana, and Karnataka is \u201chefty,\u201d which means there is a higher investment in tech-related tools, according to Mogra. In contrast, he said, the budgets are much smaller in Bihar. \u201cWhile only a handful of parties embrace technology fully,\u201d some are willing to invest up to 20% of their total campaign budget on communication tools like WhatsApp and an AI-enabled interactive voice response system, he said. As parties pump more money into AI campaign materials, there are risks that the technology might be misused, Mogra said. He said he knows of some politicians who are planning to launch defamatory attacks using AI-generated content. Deepfake experts have previously told   that AI   when politicians want to distance themselves from unflattering content. AI is still in its infancy, according to Mogra. It does not have the same impact as on-the-ground campaigning because it currently plays only \u201ca supporting part,\u201d he said. \u201cIn the next elections of 2029, AI will be a big thing, but right now, it is only in the experimental phase.\u201d", "pub_datetime": "2024-04-30", "author": "Fahad Shah", "images": [], "ner": {"Person": [], "Organization": [], "Location": []}},
{"title": "Indian politicians are bringing the dead on the campaign trail, with help from AI", "url": "https://restofworld.org/2024/dead-relatives-ai-deepfake-india/", "body": "Last month, movie star-turned-politician Vijay Vasanth was campaigning in an open jeep under an unforgiving sun in the sleepy fishing town of Kanniyakumari, the southernmost tip of the Indian mainland. He periodically waved to the fisherfolk lined up on either side of the street. Sometimes, as the vehicle slowed down, kids clambered up the bonnet and tugged at his sleeves for sweets that he kept in a container up front. It\u2019s classic electoral campaigning. And it\u2019s hard work.\u00a0 But in a hyper-wired world, it\u2019s no longer considered enough.\u00a0 Vasanth\u2019s campaign manager, a young man in his 20s, pulled out his phone to show me a video in which a gentleman in a crisp white kurta and neatly folded scarf leans back against a tall chair. He is H. Vasanth Kumar \u2014 the candidate\u2019s father, a local businessman, and the previous parliamentary representative of this constituency. Except Kumar is no longer alive. He died from Covid-19 four years ago. Kumar, who began his career as a salesman before starting a successful consumer goods company, typically had billboards across Kanniyakumari plastered with images of him advertising his business. His son\u2019s campaign team wants to recreate the familiarity of those images. In the video, Kumar, speaking in Tamil, explains how \u201cthough I died, my soul is still with all of you.\u201d He goes on to extol the virtues of his son: \u201cI can assure you that my son, Vijay, will work for the betterment of Kanniyakumari and for the progress of your children.\u201d As elections in India get in full swing, the country\u2019s leading politicians and their brand gurus have gone all in on artificial intelligence to resurrect the past and manage the future. Digital rights activists have questioned the ethics of using a deceased politician\u2019s voice or form in elections. There\u2019s the question of rights \u2014 who owns their legacy? \u2014 but more importantly, there\u2019s a humanizing aspect to \u201csoft fakes,\u201d as they are called. No one wants to speak ill of the dead, especially in India, where we have been culturally shaped to only eulogize those no longer with us. In January this year,  , the patriarch of politics in the southern state of Tamil Nadu, first appeared in an AI video at a conference for his party\u2019s youth wing. In the clip, he wore the look for which he is best remembered: a luminous yellow scarf and oversized dark glasses. Even his head was tilted, just slightly to one side, to replicate a familiar stance from real life. Two days later, he made another appearance at the book launch of a colleague\u2019s memoirs. Karunanidhi died in 2018. \u201cThe idea is to enthuse party cadres,\u201d Salem Dharanidharan, a spokesperson for the Dravida Munnetra Kazhagam (DMK) \u2014 the party that Karunanidhi led till his death \u2014 told me. \u201cIt excites older voters among whom Kalaignar [\u201cMan of Letters,\u201d as Karunanidhi was popularly called] already has a following. It spreads his ideals among younger voters who have not seen enough of him. And it also has an entertainment factor \u2014 to recreate a popular leader who is dead.\u201d Across the world, countries are grappling with similar dilemmas. Americans, for instance, banned robocalls, or AI-generated voice calls. Fake robocalls, impersonating President Joe Biden\u2019s voice, were used to try and persuade citizens not to vote in the New Hampshire primaries. The cloning was most likely done using  , one of Silicon Valley\u2019s most successful startup stories. The company\u2019s technology was also used to generate AI videos of Imran Khan, the jailed former Pakistani prime minister. And it\u2019s open to all \u2014 no prior permissions are needed from the person being imitated. ElevenLabs separately categorizes cloning used for \u201cnon-commercial purposes,\u201d like politics and public debate. In the hurly-burly of the Indian election season, though, all this is entirely esoteric and academic. No one wants to speak ill of the dead, especially in India, where we have been culturally shaped to only eulogize those no longer with us. According to Dharanidharan, AI for politicians is a mere mechanism, much like the newspaper or printing press were back in the day. \u201cIn the 1920s, our party used newspapers as a medium to propagate ideology; in the late \u201940s up to the \u201980s, we used film and cinema; in the \u201990s, we used cable TV \u2014 and now it\u2019s AI.\u201d India\u2019s prime minister, Narendra Modi, has been an early user of an  , which translates his voice from Hindi to other languages in real time. Shashi Tharoor, a minister from the opposing Indian National Congress, conducted an interview with his  . And as AI goes mainstream, the first big quarrel between the ruling Bharatiya Janata Party and the Congress party has led to a police summons: Home Minister Amit Shah alleged that  , the Congress\u2019 recently elected chief minister in Telangana, used deepfake tech to alter a video that twisted Shah\u2019s views on affirmative action quotas. Not surprisingly, new businesses that boast about providing the ultimate   are suddenly much in demand.\u00a0 But as the lines between real and fake blur, manipulation is fast becoming a challenge \u2014 and it\u2019s far more dire than when misinformation used to be exchanged via text messages or WhatsApp forwards. Two of   had to deny that they had issued messages urging people to vote against the ruling party.\u00a0 Voters are now receiving calls from supposed local representatives who engage in a full-blown conversation about the most pressing issues in their area \u2014 except they   the call. The full impact of AI on voting choices may not be understood in this election cycle. But if effective public communication was once all about human connection and authenticity, generative AI seems to have turned that premise on its head.", "pub_datetime": "2024-05-06", "author": "Barkha Dutt", "images": [], "ner": {"Person": [], "Organization": [], "Location": []}},
{"title": "Writers and publishers in Singapore reject a government plan to train AI on their work", "url": "https://restofworld.org/2024/singapore-writers-reject-ai-training/", "body": "When the Singaporean government asked local writers if they would agree to having their work used to train a large language model, it probably did not expect the country\u2019s tiny literary community to react so fiercely. An email sent late in March said that the National Multimodal LLM Programme (NMLP) aimed to address the bias of existing LLMs that have \u201cdisproportionately large influences\u201d from Western societies. Singapore\u2019s own LLM, trained on material produced locally, would have more accurate references to the nation\u2019s history, colloquialisms, and culture and train on widely spoken languages, such as Malay, Mandarin, and Tamil, it said. However, writers such as Gwee Li Sui, one of the city\u2019s best-known literary figures, are not convinced.\u00a0 \u201cThe stages of planning [for the LLM] before writers are even considered as worth consulting do not inspire confidence that my interest will be a priority,\u201d Gwee, author of more than a dozen books, told  . There is also little clarity on how the works would be protected from being used \u201cfor purposes other than what is now claimed as public service towards cultural representation,\u201d he said. The email initially gave respondents 10 days to respond to  . But it had few details on compensation or copyright protection. So Gwee declined to let the LLM train on his works, including the first book written entirely in Singlish \u2014 a creole language that is a blend of Singaporean slang and English and is widely spoken in the country. Gwee is one of several in the city-state\u2019s tiny literary community pushing back against the government\u2019s efforts to incorporate their works into the NMLP. The S$70 million ($52 million) project, launched last December, is touted as Southeast Asia\u2019s first regional LLM and is part of Singapore\u2019s ambitious plan to become a global leader in artificial intelligence by 2030.\u00a0 The disgruntled Singaporean writers are part of a worldwide growing resistance\u00a0to the use of published works to train AI technologies. Last year, U.S. comedian Sarah Silverman joined a class-action lawsuit with other authors against OpenAI and one against Meta, accusing the companies of copyright infringement for using protected work to train AI programs. In  , more than a dozen authors, including John Grisham and George R.R. Martin, have accused OpenAI of similarly infringing on their copyrights to train the popular ChatGPT chatbot. Publishers, including  , have also   and Microsoft for the same reason. \u201cMost LLM developers have taken the stance that web-scraped data is fair game to train on.\u201d Actions such as these are rare in Asia. Earlier this year, a Chinese court found that images generated by an AI service   of a science fiction character created by a Japanese studio. But as countries, including India, Indonesia,  , and Vietnam, develop their own multilingual LLMs, there is little clarity on what material is being used for training, what copyright protections authors have, and what \u2014 if any \u2014 compensation authors will receive. Singaporean   the NMLP will be trained in 11 regional languages to capture Southeast Asia\u2019s \u201cunique linguistic characteristics and multilingual environment.\u201d Building on the existing   (South-East Asian Languages In One Network) family of LLMs, it will eventually form the basis for text-to-speech and text-to-image generative programs that can be used in translation and customer-service chatbots and other applications. The email sent on behalf of Singapore\u2019s Infocomm Media Development Authority (IMDA), the lead government agency driving the LLM project, said that all data contributed would be used solely for \u201cresearch purposes.\u201d It said it recognized that the development of AI and its impact on writers was a \u201chot-button issue\u201d but made no mention of compensation.\u00a0 Despite the writers\u2019 criticism, \u201cthis level of proactive consent-seeking is quite rare,\u201d according to Nuurrianti Jalli, an assistant professor at Oklahoma State University who has studied multilingual LLMs. \u201cMost LLM developers have taken the stance that web-scraped data is fair game to train on, without getting permission from individual copyright holders,\u201d Jalli told  . \u201cSo the Singapore government\u2019s approach stands out as unusually considerate of writers\u2019 rights. But writers understandably also want to know specifics.\u201d In response to queries, the IMDA referred   to its earlier statement to local media, where a spokesperson said the survey was \u201ca research effort to advance understanding\u201d of the project. \u201cThe intent therefore was to consult the broader community on how we might approach this,\u201d the agency had said. Singapore authorities have historically had an uneasy relationship with the arts community, banning or censoring various works over the years for contravening official guidelines on race, religion, and politics. New laws have also cracked down on  , while government grants prioritize creative works that do not \u201c \u201d of institutions.\u00a0 Now, Singaporean writers are fearful of AI misusing their work with government sanction. \u201cThe work of authors, translators, and publishers in Singapore and the rest of Southeast Asia ought to be treated with due respect,\u201d New York\u2013based literary organization Singapore Unbound  in response to the IMDA survey, which it did not receive  \u201cIt is not merely data for the machines, but the living tissue of our societies,\u201d it said. There are also \u201clots of gray areas\u201d when it comes to copyright, and the legal status of training LLMs on copyrighted content is still uncertain, Peter Schoppert, director of National University of Singapore Press, an academic publisher, told  . \u201cIt is not merely data for the machines, but the living tissue of our societies.\u201d \u201cNeither Singapore\u2019s text-and-data-mining exception nor the fair-use provisions in its   would allow the training of LLMs that can then generate works without consent, credit, and compensation from copyright holders,\u201d he said, adding that this is an interpretation that is yet to be tested in the courts. Still, countries building multilingual LLMs are contending with a paucity of high-quality data to train on, so Singapore stands to gain by getting writers on its side, said Jalli. \u201cIf key opinion leaders and writers withhold their work, the LLMs may have to rely more on lower-quality web-scraped content, which could limit their coherence and factual reliability,\u201d she said. \u201cSo getting buy-in from the local writing and creative community is important for building public trust in the technology.\u201d While some negotiations with the government have taken place, few Singaporean writers and publishers think they will make much headway.\u00a0 \u201cThe government is a juggernaut compared to us. If they want to ride roughshod over us, there is very little we can do,\u201d said a member of the publishing industry, who asked not to be named, as they were still lobbying authorities on the matter. Award-winning author Dave Chua is also resigned to the project moving ahead regardless of their sentiments, with compensation hard to come by. \u201cI think they will just try to use works that are in the public domain and when authors give permission for their work to be used without compensation,\u201d Chua told   He said yes to having his material used in the LLM training, as he is \u201ccurious\u201d to see what such an LLM would produce, he said. Singapore\u2019s founding father and former prime minister, Lee Kuan Yew, famously said that \u201cpoetry is a luxury we cannot afford,\u201d and this survivalist mindset has often dictated the government\u2019s attitude towards the arts. \u201cUltimately, our governance is a very pragmatic one,\u201d Ng Kah Gay, editor at independent publisher Ethos Books, told  . \u201cFor us to hope that the government will see our value, we also have to show our relevance to the life and culture of our current society.\u201d", "pub_datetime": "2024-05-08", "author": "Nicholas Yong", "images": [], "ner": {"Person": [], "Organization": [], "Location": []}}
]