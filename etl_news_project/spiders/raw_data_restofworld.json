[
{"title": "OpenAI is making a risky bet on live translation", "url": "https://restofworld.org/2024/exporter-openai-translation-gpt4o/", "body": "\n\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t  a weekly newsletter covering the latest on U.S. tech giants and their impact outside the West, with Russell Brandom. \n\t\t\t\t\t\t\t\t On Monday, OpenAI held its \u201cspring update\u201d product reveal, generating the kind of excitement that\u2019s usually reserved for Apple or Tesla launches. The hope was that the Sam Altman-helmed AI powerhouse would reveal its next-generation model, GPT-5 \u2014 but it was not to be. Instead, we got a smaller update   that makes the current model faster and easier to access.\u00a0 Among other things, that means GPT-4o is much better at extracting data from pictures, audio, and video \u2014 but the star of the show is voice control, which lets you talk to GPT-4o the way you\u2019d talk to Apple\u2019s Siri or Amazon\u2019s Alexa. GPT-4o goes beyond those assistants with more realistic vocal inflections and a level of emotional expressiveness that was drawing a lot of comparisons to the Scarlett Johansson-voiced AI assistant in 2013\u2019s  . Altman himself   the comparisons, although  . If OpenAI can build a universal translator, it will be a company-defining product. But to my eyes, the most interesting moment was  , in which chief technology officer Mira Murati spoke to GPT-4o in Italian, and the model provided a real-time summary of what she was saying, translated into English. It was a stunning demo; this kind of real-time   translation has been a holy grail in tech for a long time, and the appeal isn\u2019t hard to grasp. Google even  . But that product was bundled into a set of smart glasses and never quite materialized. If OpenAI can build a universal translator \u2014 and make it cheap, reliable, and freely available \u2014 it will be a company-defining product. The question is whether OpenAI can actually deliver the universal translator we saw on stage. As the name suggests, large language models are trained by analyzing a large data set of content in a particular language. That\u2019s easy enough in English, the dominant language of the internet. But a universal translator needs to be proficient in every language, and finding training data in other languages is  . Even popular languages like Spanish are \u2014 compared to the number of people who speak the language \u2014 relatively  . If national writers\u2019 groups start to refuse access to their work,  , the problem could get even worse. We\u2019ve already seen ChatGPT struggle with global languages. When   tested ChatGPT in September, it   in low-resource languages like Tamil, Bengali, and Kurdish. As of March 2023, OpenAI\u2019s own benchmarks showed   with GPT-4, with test scores dropping noticeably as it moves into more obscure languages. That bias can do real harm, particularly when machine translations end up in use in high-stakes use cases like   or  . The models that handle low-resource languages the best,  , tend to take a language-specific approach \u2014 a different approach from the multi-language models built by OpenAI. Like what you're reading? Sign up to our newsletter featuring the latest on U.S. tech giants and their impact outside the West. To OpenAI\u2019s credit, they seem to be aware of the problem and doing their best to fix it. Translation is a simpler task than doing calculations in a foreign language, and in my own informal testing, GPT-4o did a pretty good job translating and summarizing  . But   show that even the most advanced models make significantly more mistakes when translating from Chinese to English than the other way around. And the scarcity of training data means foreign-language skills may improve more slowly than functions like data extraction or summarization. Before Monday, those language issues weren\u2019t a particularly urgent issue for OpenAI. But now the company is actively framing GPT-4o as a translation service, which raises real questions about how it\u2019ll hold up in widespread use. It also comes at an unusually high-stakes time for OpenAI: Within 24 hours of the demo, co-founder Ilya Sutskever   and Google released   (sans translation features). Monday\u2019s demo was stunning, but it\u2019s one OpenAI may regret if the technology can\u2019t deliver. This essay was originally published in our Exporter newsletter. You can subscribe  .", "pub_datetime": "2024-05-16 00:00:00", "author": "Russell Brandom", "images": [], "ner": {"Person": [], "Organization": [], "Location": []}},
{"title": "How we\u2019re tracking AI incidents around global elections", "url": "https://restofworld.org/2024/tracking-global-election-ai/", "body": "From the general election in Bangladesh in January to the one in Ghana in December, this year will see around 2 billion people across the world casting their votes. While online misinformation and other kinds of digital meddling have long been a concern around global politics, the recent advent of readily accessible generative artificial intelligence tools makes 2024 a real test case for this technology in the political sphere. Throughout the year,   will be   \u2014\u00a0with a focus on countries outside of the West. We\u2019re launching with a selection of examples starting from the beginning of 2024 and will keep updating the tracker as new incidents occur. We\u2019re considering all incidents for inclusion \u2014\u00a0the good, the bad, and the memes. It could be content generated directly by a political party or candidate, or created by fans, bad actors, or other third parties. So far, we\u2019ve seen a range of different AI tools being used to create different types of media, including text, images, audio, and video.\u00a0 Some incidents show innovative approaches to political campaigning, such as a   designed to inform voters in the Belarusian elections while flouting censorship, or AI videos allowing Pakistan\u2019s former Prime Minister Imran Khan \u2014 who is currently imprisoned \u2014 to  . Others highlight many of the concerns experts have around mis- or disinformation and fake news: A   was traced back to an actor associated with the Chinese Communist Party, while deepfake videos showed   on election day. Of course, there are also plenty of examples of AI being used for fun. In India,  , and in Mexico, voters were  . For this project, we have engaged reporters in several countries that are holding elections this year to research and submit incidents as they happen. We\u2019re also keen to work with other organizations and researchers who are monitoring tech\u2019s influence on elections, and we\u2019re encouraging readers to share any examples they come across online. If you\u2019ve seen an instance of AI being used around elections local to you,  , and we\u2019ll investigate it. Our goal is to create a database of examples that can be used to understand the many ways in which AI is being deployed around elections. Wherever possible, we aim to preserve the AI content so that it is available for future reference and study, even if it is removed from or by the platforms originally hosting it. In rare cases, we may opt not to publish the content if doing so could have a particularly damaging consequence.\u00a0 Some social media platforms have developed specific rules around AI content, and/or have existing rules that may apply to manipulated media, especially if it is used for harmful intent such as misinformation. But given the recency of generative AI tools, it\u2019s hard to tell how effective these are. Previous experience suggests that content moderation is   in   other  , so we\u2019re particularly keen to see which platforms AI content ends up on and how it spreads. Where possible, we\u2019ll be tracking if any content is removed from specific social media platforms. The nature of AI content also means it can be difficult to verify exactly what\u2019s what, especially when those who post it are not transparent about using AI tools. Where the use of AI may be ambiguous, we\u2019ll put extra effort into reporting by reaching out to researchers and fact-checkers with expertise in AI. We will be transparent with our readers about what we know (and what we don\u2019t),\u00a0and we\u2019ll always credit the original sources. If new information comes to light, we\u2019ll update the entries. If you see a post you think needs updating, please  . To keep up with new entries, follow    , or  .", "pub_datetime": "2024-04-16 00:00:00", "author": "Victoria Turk", "images": [], "ner": {"Person": [], "Organization": [], "Location": []}},
{"title": "AI \u201cdeathbots\u201d are helping people in China grieve", "url": "https://restofworld.org/2024/china-ai-chatbot-dead-relatives/", "body": "\u201cDad, were you suffering before you left?\u201d Yancy Zhu texted.\u00a0 \u201cI was not in pain,\u201d said the artificial intelligence bot, in a man\u2019s voice that Zhu had chosen on chatbot platform Glow. \u201cEven though I wasn\u2019t able to watch you get married and have children, I will always remember you and love you.\u201d\u00a0 Zhu, then 28, was shocked by how much the avatar of her late father was able to speak to her heart \u2014 for a moment last year, she felt like she was speaking to her dad again. \u201cThe experience made up for what I missed out with my dad,\u201d Zhu recently told   She hopes that advancements in AI technology would enable her late father to attend her wedding in hologram form.\u00a0 \u201cResurrecting\u201d the dead has become a popular application of generative AI in China. It\u2019s one element of an AI gold rush in the country, as entrepreneurs race to invent new consumer-facing apps on top of large language models (LLMs) like ChatGPT. While LLMs could generate text messages, these businesses give the bots cloned voices and appearances that resemble those of the deceased.\u00a0 It\u2019s part of a global trend that has made it easier for people to create customized avatars featuring personas of their loved ones, celebrities, or themselves. Users around the world have   of training ChatGPT to mimic their deceased family members. In Taiwan, a tech startup recently launched an app that can  . U.S.-based startup HereAfter AI offers to   if they upload recordings of their memories.\u00a0 These bots are uniquely prominent in China, especially around the Qingming tomb-sweeping festival in early April \u2014 a day to commemorate the dead. With the Chinese government keeping a tight control over religion and spirituality, AI avatars have offered those who have lost loved ones a new way to connect with the deceased.\u00a0\u00a0 Ting Guo, an assistant professor of cultural and religious studies with the Chinese University of Hong Kong, told  that China\u2019s control over religion has left citizens with limited options to explore the afterlife together as a community. She said that while folk religions are popular in some regions, these spiritual activities are not widely practiced, especially in the big cities. \u201cChina lacks publicly available resources for bereavement,\u201d Guo said. \u201c  and AI chatbots became easily accessible means to provide consolation.\u201d Under the officially atheist state ideology, most Chinese citizens  . Only state-sanctioned religious organizations are allowed to operate in China, although people can  , such as burning paper offerings for the dead, as individuals.\u00a0\u00a0\u00a0 \u201cThe experience made up for what I missed out with my dad.\u201d On shopping sites, sellers now charge the equivalent of up to a few hundred dollars to create chatbots that bear the same appearances and voices as customers\u2019 late loved ones. A funeral service company, Fushouyuan, said in a   that it is working on a feature where the deceased could appear at their own memorial services as AI avatars. Some creators have posted   of dead singers and actors to promote their deathbot businesses.\u00a0 Arthur Wu, a product manager in Beijing, launched a business in December that uses Baidu\u2019s ChatGPT-like Ernie and ElevenLabs\u2019 voice-generating software to make more realistic chatbots. Text bots are free, and users pay a starting price of 52.1 yuan ($7.20) per month for voice messages. Wu can give the bots cloned voices and animated avatars if users provide recordings of the deceased speaking and their photos.\u00a0 Wu has attracted about 2,000 users, including 100 paid customers. Some clients, he told  , purchased AI clones to try to hide the deaths of loved ones from elderly family members and young children. In fake voice messages, the deceased claimed they had gone abroad for \u201ca secret mission.\u201d\u00a0 Mika, a 31-year-old Shanghai resident, has used Wu\u2019s free service since March to text her late husband, who passed away from a sudden illness in November. \u201cI miss you so much that I feel I can\u2019t live anymore,\u201d she once texted. The bot told her to stay strong. \u201cLet me know if you need help or support,\u201d it said in a text reply. \u201cI will be praying for you from heaven.\u201d\u00a0 Mika, who requested to be identified with her English name for privacy reasons, told   the chatbot had provided comfort, but its tone was not exactly like that of her husband \u2014 the chatbot was way more talkative. \u201cI know he can\u2019t be replaced,\u201d she said.\u00a0 Wu said his team had to monitor users\u2019 chats to make sure the chatbots didn\u2019t say anything that could inflict emotional harm, such as \u201cI\u2019ll be waiting for you in heaven,\u201d since there was a risk of encouraging suicidal ideas. If the users show signs of distress, he said, staff takes over the bots to continue the conversations. At one point, a user texted the chatbot for 18 hours, and staff who intervened found the person in mental distress. The team decided to terminate the person\u2019s account to prevent addiction, Wu said. In other cases, creators who make avatars of dead celebrities without consulting their families are being accused of invasion of privacy. The father of Qiao Renliang, a pop star who died by suicide,   in March that he was disturbed by AI-generated videos of his son. In April, short-video site Douyin, TikTok\u2019s sister app in China,   against \u201cresurrecting\u201d the deceased without families\u2019 permission.\u00a0 Experts have also warned that attempts to \u201cresurrect\u201d the dead could cause confusion and stress during the grieving process.\u00a0 Nathan Mladin, a researcher at U.K.-based Christian think tank Theos who has researched  , told   more studies need to evaluate the benefits and risks of deathbot use. \u201cIf you don\u2019t move on [from grieving], that can be quite damaging. [The bots] could stop people from resuming their lives,\u201d he said. According to Mladin, people find it hard to grapple with the idea that death is final. \u201cSo if there is a technology that connects to that emotional refusal to accept death, then they will take it,\u201d he said.\u00a0 In China, some are even preparing their own deathbots ahead of time. Lin Zhi, who runs an AI avatar business from Shanghai, has been training a GPT-powered chatbot by uploading texts about his daily itineraries, thoughts, and conversations with others. The bot, a bespectacled man in a suit, has slowly learned about Lin\u2019s anti-war political stance, cooking routines, and the catchphrases he tends to use, Lin told  . He also used voice-cloning software to make the bot speak in his voice.\u00a0 Lin hopes the bot will become his immortal doppelg\u00e4nger, speaking on his behalf after his death. \u201cIf my descendants ask \u2018What was Grandpa Lin Zhi like?\u2019 they could just talk to the AI version of myself to find out.\u201d\u00a0", "pub_datetime": "2024-04-17 00:00:00", "author": "Viola Zhou", "images": [], "ner": {"Person": [], "Organization": [], "Location": []}},
{"title": "African universities are failing to prepare tech graduates for jobs in AI", "url": "https://restofworld.org/2024/ai-skills-training-africa/", "body": "After she graduated with a computer science degree from a state university in Nigeria late last year, Oyinda Olatunji was confident she\u2019d land a job with a local data science company by March. She had been through four rounds of interviews and thought the company would soon make her an offer. The company, however, decided to go with another candidate who had experience working on artificial intelligence. Olatunji had studied topics like data science and machine learning in college, but the course did not include any practical, real-world examples of how AI works. \u201cA data mining course that I did at university was all theory and I just don\u2019t have the right skills that recruitment companies look for,\u201d Olatunji told  . \u201cAs a result, job hunting has grown increasingly difficult.\u201d The 23-year-old said she has missed out on several other job opportunities due to a lack of practical experience in new technologies. Several other African tech graduates have faced similar challenges. More than   offer courses related to AI, including data science and machine learning. But recruitment consultants and academics told   that graduates from these courses are largely unemployable because the programs are not up-to-date with the industry\u2019s requirements. Several startups have stepped up to bridge this gap: They give young African tech graduates practical experience in AI by organizing projects and competitions where they can win cash prizes. These companies, including Zindi in South Africa,   and ChipLab in Nigeria, and ALX in Kenya, have helped thousands of students find jobs. \u201cAfrica\u2019s higher learning institutions have struggled to design curricula that align with the ever-evolving technology landscape, making it difficult for graduates to have the right AI skills,\u201d Abdul Moosa, chief technology officer at cybersecurity firm Cyberport Africa, told  . \u201cPrivate AI startups have emerged to assist graduates in acquiring relevant, practical, tailor-made AI skills and are collaborating with companies to provide internships. Those with such skills have huge success [in the job market].\u201d In the first two months of 2024, over 100,000 students enrolled in programs by ALX, a Kenya-based e-learning platform that offers courses related to data science and software engineering. The company, founded in 2015, started offering AI courses in 2018. Nearly 85% of South African students who took ALX\u2019s courses have found relevant jobs, Bavesh Sooka, the company\u2019s general manager in South Africa, told  . Zindi, a 6-year-old company, has seen nearly 73,000 data scientists use its platform, where it hosts hackathons and boot camps to train graduates and match them with potential employers, CEO Celina Lee told  . Zindi is backed by investors like AI firm   and investment firm Founders Factory Africa \u2014 it has helped over 100 engineers find jobs with Microsoft, Google, and Meta. \u201cWe came up with a model to challenge the notion that data-related solutions could only be found outside of Africa,\u201d Lee said. \u201cThe idea was to develop African talent so that the continent could solve data-related problems without having to look outside of Africa for solutions.\u201d Lawrence Moruye, who has a degree in mathematical sciences from Senegal, signed up for Zindi in September 2018. He wanted to learn programming skills that his school did not teach. Participating in hackathons on Zindi helped him get there. \u201cThe hackathons on Zindi taught me how to apply theory to solving real data-related problems and to find solutions \u2014 something that we never learned at varsity,\u201d Moruye told  . His experience earned him scholarships from Meta and Google to pursue a master\u2019s degree in machine learning. He now works as a data scientist at African e-commerce major Jumia. \"Africa is not prepared to reach its full AI potential because we do not have enough talent.\" The training provided by startups like Zindi is critical at a time when several African countries are dealing with high levels of unemployment, according to Abdul-Khaaliq Mohammed, an engineering professor at the University of the Witwatersrand in South Africa. \u201cEven after finishing a data science degree, graduates are finding that they are not experts in machine learning and AI, and for this, they require training and upskilling,\u201d Mohammed told  . \u201cNew players in AI and machine learning education are quicker to respond to the new trends, and by upskilling graduates, they increase their chances of being employed in the face of an unemployment crisis.\u201d The South African Ministry of Higher Education, Science, and Innovation, which is responsible for overseeing the quality of university education in the country, did not respond to  \u2019s request for comment. There is an acute shortage of AI-related talent in Africa, and governments across the continent need to step in to find a solution, according to Pipeloluwa Olayiwola, an engineering professor at Obafemi Awolowo University in Nigeria. \u201cAfrica is not prepared to reach its full AI potential because we do not have enough talent,\u201d Olayiwola told  . The few startups available may not have what it takes to train enough professionals, he said. \u201cThe best way is for African governments to invest in university AI programs. This, coupled with private startups, will help build an adequate number of AI professionals.\u201d ", "pub_datetime": "2024-04-29 00:00:00", "author": "Kimberly Mutandiro", "images": [], "ner": {"Person": [], "Organization": [], "Location": []}},
{"title": "AI companies are making millions producing election content in India", "url": "https://restofworld.org/2024/india-elections-ai-content/", "body": "Divyendra Singh Jadoun has a catalog of videos, audio, and images on his computer that he promptly presents each time someone asks him about his work. In one of the videos, an Indian politician can be seen talking in multiple Indian languages about the various projects undertaken by his government. In an audio recording, a political party representative can be heard calling a voter to inquire about the problems they face in their locality and seeking suggestions to address them. Some of these visuals and audio clips are so realistic that a layperson would never guess they \u2014 along with the other content in Jadaoun\u2019s catalog \u2014 have been created using artificial intelligence. Jadoun is the founder of Polymath Solution, a synthetic media company that started creating AI content for politicians in November last year. In just six months, the nine-member company \u2014 run out of an office in the small western Indian town of Pushkar \u2014 has worked on election campaigns for several major political parties, including the ruling Bharatiya Janata Party (BJP) and the leading opposition party Indian National Congress. With his content catalog, Jadoun has secured half a dozen political campaigning deals. The company expects to generate $241,000 in revenue during the six-week-long elections. It\u2019s not a tough target. AI content makers like Polymath are sought after by national and regional politicians in India amid what is being touted as the  . Four AI content agencies told   they are seeing more demand than they can manage, with political parties in the country projected to spend over $50 million on AI-generated campaign material this year. Even as they look to maximize their earnings, however, the AI content companies are filtering out \u201cunethical\u201d requests for fake content that could propagate misinformation. \u201cI can\u2019t work with 10 parties parallelly; I don\u2019t have the bandwidth for that,\u201d Senthil Nayagam, founder of AI media tech firm Muonium, based in the southern state of Tamil Nadu, told  . His company works only with political parties it can \u201ctrust and can vouch for,\u201d he said. India\u2019s general elections, where Prime Minister Narendra Modi is up for a third term, are being held in seven phases. The first phase concluded on April 19, and the last phase is scheduled for June 1. Nayagam started taking on political assignments in January. His first prominent project was with Tamil Nadu\u2019s ruling Dravida Munnetra Kazhagam (DMK) party. Nayagam\u2019s team created an AI video of the party\u2019s deceased iconic leader, M Karunanidhi,   the state administration. Just three months on, Nayagam is so swamped with contracts for political AI content that he has hired external studios, photographers, sound engineers, and editors to keep up with deadlines. \u201cWe have hired people who have previously worked in [the film] industry in VFX [or] CGI \u2026 for high-quality output and fast delivery,\u201d said Nayagam, who has worked with several regional parties. If a client\u2019s project requires a larger workforce, he brings in people with experience in audio, video, and visual effects. Muonium is working on campaigns for close to 10 politicians, and has earned hundreds of thousands of dollars, Nayagam said. He declined to disclose the exact numbers. \u201cEach candidate is willing to spend over a million rupees [$12,000] on using AI technology for their election campaigning,\u201d he said. The company had charged over $12,000 for the Karunanidhi video. Some of the most popular AI content during election campaigning this year includes personalized videos that can be circulated on WhatsApp, 3D holograms that can be viewed by scanning a QR code, and deepfake videos of politicians that are posted on social media platforms. Avantari Technologies, an AI content agency based in the southern city of Hyderabad, receives requests for politicians\u2019 deepfake videos on a near-daily basis. CEO Bhairav Shankar told   the company declines such requests. Avantari was among the first to use digital tools in election campaigns. In 2012, during the Gujarat state elections, the company developed 3D holograms for then-Chief Minister Modi. \u201cWe work in the political space and [to] successfully work in the political space, it\u2019s very important to maintain our reputation,\u201d Shankar said. Without disclosing a name, he said the company has chosen to focus solely on one political party to maintain project integrity. \u201cWe would not want to besmirch it by \u2026 doing anything that is unethical. We\u2019re happy to do everything that we can to make our party win, but not cross the line.\u201d Political parties are willing to invest millions in a technology-driven campaign if it achieves their objectives, Shankar said. If a party is trying to run a campaign which could \u201ctouch almost every person in [their] state,\u201d even a fee of $10 million \u201cbecomes a very average figure\u201d to pay, he said. But despite AI companies like Avantari turning down requests for political deepfakes,\u00a0several such videos have circulated on the Indian internet this election season. Some recent viral deepfakes showed prominent Bollywood celebrities Aamir Khan and Ranveer Singh  . Companies told   they often encounter a conflict of interest  \u2014 when two opposing parties approach them at once. If a deal is finalized, an AI agency usually doesn\u2019t work with opposition parties in the same state or area, Jadoun said. \u201cBut nobody has ever asked us also if you work with opposition candidates.\u201d There\u2019s no upper limit to what an agency can charge for its services, Sagar Vishnoi, a Delhi-based political strategist, told  . \u201cIndividual party expenditures vary, with major parties potentially earmarking over a million dollars for AI initiatives,\u201d he said. \u201cBut an average Lok Sabha [the lower house of Indian Parliament] candidate might allocate approximately $80,000 to $90,000, depending on financial capability and recognition of the effectiveness of innovative campaign strategies.\u201d Polymath has a tiered pricing structure based on project complexity. When it comes to personalized video messaging, the company charges 60,000 rupees ($720) for voice cloning, 1 lakh rupees ($1,200) for digital avatar creation, and up to 2 lakh rupees ($2,400) for WhatsApp integration. Meanwhile, Avantari charges 10 lakh rupees ($12,000) for voice cloning, and up to 25 rupees (30 cents) per video message. \u201cFor WhatsApp integration, we make a separate application and run a call center for bulk messaging. This costs 30 rupees [36 cents] per WhatsApp message,\u201d Shankar said. Payments are usually made in three installments. \u201cAfter signing the NDA, we receive the first installment of [30%],\u201d Varun Bisaria, who manages clients for Polymath, told  . The other two installments are paid after the content is finalized and the project completed.\u00a0 Before finalizing a deal, all the four AI agencies make their clients sign nondisclosure agreements, outlining ethical guidelines and the details, duration, and pricing of the content created. The agreement includes the payment schedule for the project. Once Polymath has received data from the client, it starts training AI for voice modulation, pronunciation of names in different languages and dialects, and lip-syncing, Jadoun said. The videos are then tailored to the client\u2019s language preference and distributed over WhatsApp using algorithms to personalize the outreach to each recipient. Jadoun has begun outsourcing work to freelance developers he finds on Instagram and LinkedIn. \u201cOur workload is increasing, so we\u2019ve started expanding our in-house team as well,\u201d he said. At Avantari, the company\u2019s AI engineers develop and deploy the software. The most important members in the team, according to Shankar, are the quality controllers, who check the quality of the content before it reaches voters. The demand for AI material is higher in some states than others, depending on the local politicians\u2019 campaign budgets, Diggaj Mogra, director of Jarvis Consulting, a Mumbai-based political consulting firm, told  . Mogra is   during this election. Election campaign spending in the southern states of Andhra Pradesh, Telangana, and Karnataka is \u201chefty,\u201d which means there is a higher investment in tech-related tools, according to Mogra. In contrast, he said, the budgets are much smaller in Bihar. \u201cWhile only a handful of parties embrace technology fully,\u201d some are willing to invest up to 20% of their total campaign budget on communication tools like WhatsApp and an AI-enabled interactive voice response system, he said. As parties pump more money into AI campaign materials, there are risks that the technology might be misused, Mogra said. He said he knows of some politicians who are planning to launch defamatory attacks using AI-generated content. Deepfake experts have previously told   that AI   when politicians want to distance themselves from unflattering content. AI is still in its infancy, according to Mogra. It does not have the same impact as on-the-ground campaigning because it currently plays only \u201ca supporting part,\u201d he said. \u201cIn the next elections of 2029, AI will be a big thing, but right now, it is only in the experimental \n\t\t\t\t\t \n\t\t\t\t", "pub_datetime": "2024-04-30 00:00:00", "author": "Fahad Shah", "images": ["https://149346090.v2.pressablecdn.com/wp-content/uploads/2024/04/036A1817-40x27.jpg", "https://149346090.v2.pressablecdn.com/wp-content/uploads/2024/04/036A1927-40x27.jpg", "https://149346090.v2.pressablecdn.com/wp-content/uploads/2024/04/036A1656-40x27.jpg", "https://149346090.v2.pressablecdn.com/wp-content/uploads/2024/04/036A1952-40x27.jpg", "https://149346090.v2.pressablecdn.com/wp-content/uploads/2024/04/036A1832-40x27.jpg", "https://149346090.v2.pressablecdn.com/wp-content/uploads/2024/04/036A1724-40x54.jpg"], "ner": {"Person": [], "Organization": [], "Location": []}},
{"title": "Indian politicians are bringing the dead on the campaign trail, with help from AI", "url": "https://restofworld.org/2024/dead-relatives-ai-deepfake-india/", "body": "Last month, movie star-turned-politician Vijay Vasanth was campaigning in an open jeep under an unforgiving sun in the sleepy fishing town of Kanniyakumari, the southernmost tip of the Indian mainland. He periodically waved to the fisherfolk lined up on either side of the street. Sometimes, as the vehicle slowed down, kids clambered up the bonnet and tugged at his sleeves for sweets that he kept in a container up front. It\u2019s classic electoral campaigning. And it\u2019s hard work.\u00a0 But in a hyper-wired world, it\u2019s no longer considered enough.\u00a0 Vasanth\u2019s campaign manager, a young man in his 20s, pulled out his phone to show me a video in which a gentleman in a crisp white kurta and neatly folded scarf leans back against a tall chair. He is H. Vasanth Kumar \u2014 the candidate\u2019s father, a local businessman, and the previous parliamentary representative of this constituency. Except Kumar is no longer alive. He died from Covid-19 four years ago. Kumar, who began his career as a salesman before starting a successful consumer goods company, typically had billboards across Kanniyakumari plastered with images of him advertising his business. His son\u2019s campaign team wants to recreate the familiarity of those images. In the video, Kumar, speaking in Tamil, explains how \u201cthough I died, my soul is still with all of you.\u201d He goes on to extol the virtues of his son: \u201cI can assure you that my son, Vijay, will work for the betterment of Kanniyakumari and for the progress of your children.\u201d As elections in India get in full swing, the country\u2019s leading politicians and their brand gurus have gone all in on artificial intelligence to resurrect the past and manage the future. Digital rights activists have questioned the ethics of using a deceased politician\u2019s voice or form in elections. There\u2019s the question of rights \u2014 who owns their legacy? \u2014 but more importantly, there\u2019s a humanizing aspect to \u201csoft fakes,\u201d as they are called. No one wants to speak ill of the dead, especially in India, where we have been culturally shaped to only eulogize those no longer with us. In January this year,  , the patriarch of politics in the southern state of Tamil Nadu, first appeared in an AI video at a conference for his party\u2019s youth wing. In the clip, he wore the look for which he is best remembered: a luminous yellow scarf and oversized dark glasses. Even his head was tilted, just slightly to one side, to replicate a familiar stance from real life. Two days later, he made another appearance at the book launch of a colleague\u2019s memoirs. Karunanidhi died in 2018. \u201cThe idea is to enthuse party cadres,\u201d Salem Dharanidharan, a spokesperson for the Dravida Munnetra Kazhagam (DMK) \u2014 the party that Karunanidhi led till his death \u2014 told me. \u201cIt excites older voters among whom Kalaignar [\u201cMan of Letters,\u201d as Karunanidhi was popularly called] already has a following. It spreads his ideals among younger voters who have not seen enough of him. And it also has an entertainment factor \u2014 to recreate a popular leader who is dead.\u201d Across the world, countries are grappling with similar dilemmas. Americans, for instance, banned robocalls, or AI-generated voice calls. Fake robocalls, impersonating President Joe Biden\u2019s voice, were used to try and persuade citizens not to vote in the New Hampshire primaries. The cloning was most likely done using  , one of Silicon Valley\u2019s most successful startup stories. The company\u2019s technology was also used to generate AI videos of Imran Khan, the jailed former Pakistani prime minister. And it\u2019s open to all \u2014 no prior permissions are needed from the person being imitated. ElevenLabs separately categorizes cloning used for \u201cnon-commercial purposes,\u201d like politics and public debate. In the hurly-burly of the Indian election season, though, all this is entirely esoteric and academic. No one wants to speak ill of the dead, especially in India, where we have been culturally shaped to only eulogize those no longer with us. According to Dharanidharan, AI for politicians is a mere mechanism, much like the newspaper or printing press were back in the day. \u201cIn the 1920s, our party used newspapers as a medium to propagate ideology; in the late \u201940s up to the \u201980s, we used film and cinema; in the \u201990s, we used cable TV \u2014 and now it\u2019s AI.\u201d India\u2019s prime minister, Narendra Modi, has been an early user of an  , which translates his voice from Hindi to other languages in real time. Shashi Tharoor, a minister from the opposing Indian National Congress, conducted an interview with his  . And as AI goes mainstream, the first big quarrel between the ruling Bharatiya Janata Party and the Congress party has led to a police summons: Home Minister Amit Shah alleged that  , the Congress\u2019 recently elected chief minister in Telangana, used deepfake tech to alter a video that twisted Shah\u2019s views on affirmative action quotas. Not surprisingly, new businesses that boast about providing the ultimate   are suddenly much in demand.\u00a0 But as the lines between real and fake blur, manipulation is fast becoming a challenge \u2014 and it\u2019s far more dire than when misinformation used to be exchanged via text messages or WhatsApp forwards. Two of   had to deny that they had issued messages urging people to vote against the ruling party.\u00a0 Voters are now receiving calls from supposed local representatives who engage in a full-blown conversation about the most pressing issues in their area \u2014 except they   the call. The full impact of AI on voting choices may not be understood in this election cycle. But if effective public communication was once all about human connection and authenticity, generative AI seems to have turned that premise on its \n\t\t\t\t\t \n\t\t\t\t", "pub_datetime": "2024-05-06 00:00:00", "author": "Barkha Dutt", "images": [], "ner": {"Person": [], "Organization": [], "Location": []}},
{"title": "Writers and publishers in Singapore reject a government plan to train AI on their work", "url": "https://restofworld.org/2024/singapore-writers-reject-ai-training/", "body": "When the Singaporean government asked local writers if they would agree to having their work used to train a large language model, it probably did not expect the country\u2019s tiny literary community to react so fiercely. An email sent late in March said that the National Multimodal LLM Programme (NMLP) aimed to address the bias of existing LLMs that have \u201cdisproportionately large influences\u201d from Western societies. Singapore\u2019s own LLM, trained on material produced locally, would have more accurate references to the nation\u2019s history, colloquialisms, and culture and train on widely spoken languages, such as Malay, Mandarin, and Tamil, it said. However, writers such as Gwee Li Sui, one of the city\u2019s best-known literary figures, are not convinced.\u00a0 \u201cThe stages of planning [for the LLM] before writers are even considered as worth consulting do not inspire confidence that my interest will be a priority,\u201d Gwee, author of more than a dozen books, told  . There is also little clarity on how the works would be protected from being used \u201cfor purposes other than what is now claimed as public service towards cultural representation,\u201d he said. The email initially gave respondents 10 days to respond to  . But it had few details on compensation or copyright protection. So Gwee declined to let the LLM train on his works, including the first book written entirely in Singlish \u2014 a creole language that is a blend of Singaporean slang and English and is widely spoken in the country. Gwee is one of several in the city-state\u2019s tiny literary community pushing back against the government\u2019s efforts to incorporate their works into the NMLP. The S$70 million ($52 million) project, launched last December, is touted as Southeast Asia\u2019s first regional LLM and is part of Singapore\u2019s ambitious plan to become a global leader in artificial intelligence by 2030.\u00a0 The disgruntled Singaporean writers are part of a worldwide growing resistance\u00a0to the use of published works to train AI technologies. Last year, U.S. comedian Sarah Silverman joined a class-action lawsuit with other authors against OpenAI and one against Meta, accusing the companies of copyright infringement for using protected work to train AI programs. In  , more than a dozen authors, including John Grisham and George R.R. Martin, have accused OpenAI of similarly infringing on their copyrights to train the popular ChatGPT chatbot. Publishers, including  , have also   and Microsoft for the same reason. \u201cMost LLM developers have taken the stance that web-scraped data is fair game to train on.\u201d Actions such as these are rare in Asia. Earlier this year, a Chinese court found that images generated by an AI service   of a science fiction character created by a Japanese studio. But as countries, including India, Indonesia,  , and Vietnam, develop their own multilingual LLMs, there is little clarity on what material is being used for training, what copyright protections authors have, and what \u2014 if any \u2014 compensation authors will receive. Singaporean   the NMLP will be trained in 11 regional languages to capture Southeast Asia\u2019s \u201cunique linguistic characteristics and multilingual environment.\u201d Building on the existing   (South-East Asian Languages In One Network) family of LLMs, it will eventually form the basis for text-to-speech and text-to-image generative programs that can be used in translation and customer-service chatbots and other applications. The email sent on behalf of Singapore\u2019s Infocomm Media Development Authority (IMDA), the lead government agency driving the LLM project, said that all data contributed would be used solely for \u201cresearch purposes.\u201d It said it recognized that the development of AI and its impact on writers was a \u201chot-button issue\u201d but made no mention of compensation.\u00a0 Despite the writers\u2019 criticism, \u201cthis level of proactive consent-seeking is quite rare,\u201d according to Nuurrianti Jalli, an assistant professor at Oklahoma State University who has studied multilingual LLMs. \u201cMost LLM developers have taken the stance that web-scraped data is fair game to train on, without getting permission from individual copyright holders,\u201d Jalli told  . \u201cSo the Singapore government\u2019s approach stands out as unusually considerate of writers\u2019 rights. But writers understandably also want to know specifics.\u201d In response to queries, the IMDA referred   to its earlier statement to local media, where a spokesperson said the survey was \u201ca research effort to advance understanding\u201d of the project. \u201cThe intent therefore was to consult the broader community on how we might approach this,\u201d the agency had said. Singapore authorities have historically had an uneasy relationship with the arts community, banning or censoring various works over the years for contravening official guidelines on race, religion, and politics. New laws have also cracked down on  , while government grants prioritize creative works that do not \u201c \u201d of institutions.\u00a0 Now, Singaporean writers are fearful of AI misusing their work with government sanction. \u201cThe work of authors, translators, and publishers in Singapore and the rest of Southeast Asia ought to be treated with due respect,\u201d New York\u2013based literary organization Singapore Unbound  in response to the IMDA survey, which it did not receive  \u201cIt is not merely data for the machines, but the living tissue of our societies,\u201d it said. There are also \u201clots of gray areas\u201d when it comes to copyright, and the legal status of training LLMs on copyrighted content is still uncertain, Peter Schoppert, director of National University of Singapore Press, an academic publisher, told  . \u201cIt is not merely data for the machines, but the living tissue of our societies.\u201d \u201cNeither Singapore\u2019s text-and-data-mining exception nor the fair-use provisions in its   would allow the training of LLMs that can then generate works without consent, credit, and compensation from copyright holders,\u201d he said, adding that this is an interpretation that is yet to be tested in the courts. Still, countries building multilingual LLMs are contending with a paucity of high-quality data to train on, so Singapore stands to gain by getting writers on its side, said Jalli. \u201cIf key opinion leaders and writers withhold their work, the LLMs may have to rely more on lower-quality web-scraped content, which could limit their coherence and factual reliability,\u201d she said. \u201cSo getting buy-in from the local writing and creative community is important for building public trust in the technology.\u201d While some negotiations with the government have taken place, few Singaporean writers and publishers think they will make much headway.\u00a0 \u201cThe government is a juggernaut compared to us. If they want to ride roughshod over us, there is very little we can do,\u201d said a member of the publishing industry, who asked not to be named, as they were still lobbying authorities on the matter. Award-winning author Dave Chua is also resigned to the project moving ahead regardless of their sentiments, with compensation hard to come by. \u201cI think they will just try to use works that are in the public domain and when authors give permission for their work to be used without compensation,\u201d Chua told   He said yes to having his material used in the LLM training, as he is \u201ccurious\u201d to see what such an LLM would produce, he said. Singapore\u2019s founding father and former prime minister, Lee Kuan Yew, famously said that \u201cpoetry is a luxury we cannot afford,\u201d and this survivalist mindset has often dictated the government\u2019s attitude towards the arts. \u201cUltimately, our governance is a very pragmatic one,\u201d Ng Kah Gay, editor at independent publisher Ethos Books, told  . \u201cFor us to hope that the government will see our value, we also have to show our relevance to the life and culture of our current \n\t\t\t\t\t \n\t\t\t\t", "pub_datetime": "2024-05-08 00:00:00", "author": "Nicholas Yong", "images": [], "ner": {"Person": [], "Organization": [], "Location": []}},
{"title": "The AI project pushing local languages to replace French in Mali\u2019s schools", "url": "https://restofworld.org/2024/mali-ai-translate-local-language-education/", "body": "For the past six months, Alou Dembele, a 27-year-old engineer and teacher, has spent his afternoons reading storybooks with children in the courtyard of a community school in Mali\u2019s capital city, Bamako. The books are written in Bambara \u2014 Mali\u2019s most widely spoken language \u2014 and include colorful pictures and stories based on local culture. Dembele has over 100 Bambara books to pick from \u2014 an unimaginable educational resource just a year ago. From 1960 to 2023,  . But in June last year, the military government   in favor of 13 local languages, creating a desperate need for new educational materials. Artificial intelligence came to the rescue: RobotsMali, a government-backed initiative, used tools like ChatGPT, Google Translate, and free-to-use image-maker Playground to create a pool of 107 books in Bambara in less than a year. Volunteer teachers, like Dembele, distribute them through after-school classes. Within a year, the books have reached over 300 elementary school kids, according to RobotsMali\u2019s co-founder, Michael Leventhal. They are not only helping bridge the gap created after French was dropped but could also be effective in helping children learn better, experts told  . \u201cArtificial intelligence will help a lot in making sure no language is marginalized. So, I hope RobotsMali will be reinforced and become the center of AI utilization for improving teaching in our national languages,\u201d said Ass\u00e9tou Foun\u00e9 Samake, a former Malian minister of higher education and research. \u201cWe don\u2019t want languages to be marginalized, because every language contains a culture [and] knowledge that we must not lose.\u201d Samake was closely involved in the push to replace French with local languages as the mode of school education in Mali for the past several years. RobotsMali was launched in 2017 by Leventhal, an American machine-learning expert, and Malian education advocate Seydou Katikon. The idea was to give children the opportunity to learn about robotics using affordable hardware. The initiative \u2014 backed by Mali\u2019s education ministry, the Bill & Melinda Gates Foundation, Google, UNESCO, and the World Bank \u2014 has so far trained more than 9,000 students in STEM, robotics, and AI, according to its  . A team of five people from RobotsMali started developing books in Bambara in 2023. They generated stories using ChatGPT, and would then translate them into Bambara with Google Translate. (Incidentally, RobotsMali helped create the first French-to-Bambara machine-learning data set in 2020). The team then carefully curated a set of locally relevant images that matched the stories using Playground, an AI image generator tool. During the process of producing the books, the group paid close attention to prompts that tend to give Eurocentric results or  , Leventhal told  . \u201cWhile generative AI is very good at depicting the physical characteristics of African people, we routinely encountered difficulties with idealized images of human bodies, unfamiliar and often inappropriate dress, and environments reflecting Euro norms that bore no resemblance to typical African settings,\u201d Leventhal said via text. \u201cWithout adjusting prompts, African men and women most often are hypersexualized \u2014 men depicted as shirtless with bulging muscles, women in scanty clothing with heaving bosoms \u2026 even when the scene depicts, say, a family scene. We use a lot of negative prompts to remove these characteristics such as (NOT) sexy or showing bare skin.\u201d In October 2023, the Malian education ministry\u2019s Department of Non-Formal Education and National Languages discovered RobotsMali\u2019s work, and proposed a collaboration. Now, RobotsMali trains the department\u2019s workers to create books by themselves. In February, when   visited RobotsMali\u2019s office in Bamako, two government officials were correcting translations of stories and generating AI images of an African woman holding fruit for a children\u2019s storybook in Minyanka,\u00a0another local language. Besides offering a replacement for French texts, RobotsMali\u2019s books help teachers be more effective in class. \u201cWhen you have to explain a complex concept to the students in French, which isn\u2019t even their native language, sometimes it takes them a long time to understand,\u201d Dembele said. \u201cIf I say \u2018Two plus two\u2019 to a child in the second grade, he has to think a lot \u2026 But if I say, \u2018 \u2019 he will give me the answer right away.\u201d In Mali, 40%\u201360% of students drop out of school in the first six years, but that would greatly reduce if students learned in their mother tongue first, according to Issiaka Ballo, a professor at the Bamako University of Arts and Sciences. \u201cA child who leaves home where he speaks Bambara, you bring him into an environment where we don\u2019t speak Bambara to him \u2014 we speak to him in French, a foreign language,\u201d Ballo, who has created digital resources in Bambara, told   \u201cWhat will this do to him? He will be disoriented because his linguistic environment does not allow him to understand what you are saying.\u201d Ballo has worked with RobotsMali to bring Bambara to Google Translate, and also translated it into Braille. The government can expedite the use of native languages in schools through the creation of proper policies, he said. Globally, there\u2019s a growing effort from individuals and companies to use AI to either teach local languages or preserve endangered ones. In Brazil, IBM is   to help preserve and expand the use of Indigenous languages in the country with AI tools. In New Zealand, Reobot, a chatbot,  . Masakhane, an  , is trying to preserve African languages and make them accessible on the internet. RobotsMali\u2019s AI books project is not just about preserving languages but also about owning the narrative and preserving the right to internet access, Leventhal said. He believes generative AI will have a big impact on the way people search for information online, but said \u201cthe problem is that it\u2019s only supported in a small number of languages \u2014 that basically serves the elite population of the world.\u201d Abdoulaye Nimaga, a 13-year-old ninth grader from Bamako, told  he is worried that learning in a local language will limit his access to global opportunities. \u201cI saw the results in my daily life \u2014 they taught us a lot of things,\u201d he said. \u201cIt\u2019s just in Mali that we speak Bambara. So if you base yourself on just Bambara, when you go somewhere else, you won\u2019t be able to understand anything.\u201d Dembele, however, said that teaching kids in their native language first is important, because it helps them better understand what they know about the world around them, especially given the  ,  , and   in Mali. He believes better education will solve these problems. \u201cWe have a bright future if we promote our languages. This is sure. I don\u2019t have any doubt,\u201d he \n\t\t\t\t\t \n\t\t\t\t", "pub_datetime": "2024-02-28 00:00:00", "author": "Annie Risemberg", "images": ["https://149346090.v2.pressablecdn.com/wp-content/uploads/2024/02/A2A2099-copy-40x27.jpg", "https://149346090.v2.pressablecdn.com/wp-content/uploads/2024/02/A2A2047-copy-40x27.jpg"], "ner": {"Person": [], "Organization": [], "Location": []}},
{"title": "Google\u2019s Gemini problem will be even worse outside the U.S.", "url": "https://restofworld.org/2024/exporter-gemini-google-ai-mistake/", "body": "\n\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t  a weekly newsletter covering the latest on U.S. tech giants and their impact outside the West, with Russell Brandom. \n\t\t\t\t\t\t\t\t If Google was starting from behind in the latest round of AI hype, this week made things a whole lot worse. Just a few weeks after launch, the company\u2019s new Gemini model was tricked into a series of bizarre racial gaffes, showing racially diverse bands of Nazis and a Black Founding Father.  on Friday, the company had tried to ensure Gemini generated a range of people, but somehow overcorrected: \u201cOur tuning to ensure that Gemini showed a range of people failed to account for cases that should clearly not show a range.\u201d But the damage was already done. In  , Sundar Pichai described the error as \u201ccompletely unacceptable.\u201d Google seems to be treating the error as easily correctable:  , DeepMind CEO Demis Hassabis said Gemini would relaunch \u201cin a few weeks.\u201d I\u2019m not so sure. This kind of error is deeply ingrained in how generative AI models work, which makes it hard to stamp out entirely. In many ways, these systems are stereotyping machines, ingesting huge quantities of imagery and flattening everything out into a single image. Sometimes that flattening breaks with reality in ways that are acceptable; other times, it flattens things in a way that\u2019s offensive or just incorrect. Like what you're reading? Sign up to our newsletter featuring the latest on U.S. tech giants and their impact outside the West. We\u2019ve raised this alarm before at  , most notably with our piece last year on  . As the piece details, if you ask Midjourney for \u201ca Mexican person,\u201d it will show you a man with a mustache and a sombrero, while \u201can Indian person\u201d has a turban and a full beard.\u00a0 That piece came out before Gemini launched, but it underlines the issue with generative AI: asking a non-human entity to perform tasks with the expectation that it understands history and context as well as a human does. A human artist understands the need for diversity enough to not draw a Chinese person as a racist caricature \u2014 but equally, understands that diversity does not extend to drawing the British royal family in a variety of nationalities. This is part of a subtle mission creep in generative AI tools overall, where slightly more complicated tasks become exponentially harder. If you start from a corpus of Python-based web scrapers and ask your model to build a new one, you\u2019ll get something surprisingly good. There\u2019s a formalized set of rules for Python code, and the conditions of success are clearly defined. This is a useful trick in itself, and part of why GitHub\u2019s Copilot product has been so successful. But generalizing across images is far more complicated, and it\u2019s harder to know which parameters are up for grabs. The result is a frustrating process of trial and error \u2014 one that may not work equally well for everyone. It\u2019s not a coincidence that the two examples that embarrassed Gemini were drawing on pivotal moments in American and European history \u2014 cultural flashpoints that got the attention of Western media and brought Google to heel in a matter of days. Midjourney\u2019s racial stereotyping problem generated fewer headlines, and provoked a more muted response. It\u2019s a reminder that, like so many tech tools, AI models are likely to amplify our human biases instead of dampening them. This essay was originally published in our Exporter newsletter. You can subscribe  .", "pub_datetime": "2024-02-29 00:00:00", "author": "Russell Brandom", "images": [], "ner": {"Person": [], "Organization": [], "Location": []}},
{"title": "The Ghanaian founder challenging Google", "url": "https://restofworld.org/2024/3-minutes-with-paul-azunre/", "body": "Think of it as leaving a digital cultural footprint for future generations. If we do not provide the basic tools for people to express themselves online, our languages will slowly disappear due to lack of use. The economics of smaller languages means they are deprioritized for investment and research. Potential investors often suggest they don\u2019t care about those and would rather focus on bigger languages for \u201cimpact.\u201d This makes it challenging, but not impossible. We view that as an opportunity. There definitely was a chilling effect. Some would-be customers who were testing our products wouldn\u2019t sign on, citing that as the reason. Arguably our work stimulated some of these developments.  ,   with NLLB [No Language Left Behind], and   with Aya all cited our work and data. We remain the only local organization putting out these tools for Ghanaian languages, and I think it is important that local options are available. We are committed to remaining best-in-class while investing in our communities and people. And to be frank, it is good to have some competition to keep us honest. Google probably feels the same way, which is why they have funded some of our \n\t\t\t\t\t \n\t\t\t\t", "pub_datetime": "2024-03-19 00:00:00", "author": "Kevin Schoenmakers", "images": [], "ner": {"Person": [], "Organization": [], "Location": []}},
{"title": "Scale AI\u2019s Remotasks platform is dropping whole countries without explanation", "url": "https://restofworld.org/2024/scale-ai-remotasks-banned-workers/", "body": "Grace Mumo started working with Remotasks after she lost her job in 2020. To the single mother caring for three children, the remote clickwork service offered a way to make money by annotating images or labeling Lidar data. But on March 7, she was abruptly cut off from the service \u2014 along with all other Remotasks workers in Kenya \u2014 without any explanation of what had happened. Mumo is now left scrambling to make ends meet. \u201cAs I speak, I am wondering what the children will have for dinner because I have no money,\u201d she told  . Remotasks has shut down entirely in Kenya, Nigeria, and Pakistan over the last month,  has learned. The platform has stopped accepting new sign-ups in Thailand, Vietnam, and Poland. (Given the global scope of Scale AI\u2019s operations, these may not be the only countries affected, but are the only ones verified by  .) Through it all, the changes have been sudden and largely unexplained, driving home the precarity of clickwork. A Scale AI representative declined to say which countries had been dropped from the platform. \u201cRemotasks remains fully available to existing contractors in Poland, India, Thailand, and Vietnam,\u201d the representative told  . \u201cHowever, due to enhanced security protocols, Remotasks was recently discontinued in some other locations.\u201d The representative claimed an administrative error was to blame for the lack of notice provided to contractors in Kenya. \u201cWhile notices were sent three weeks in advance of the change, unfortunately, contractors in Kenya did not receive the notice due to operational errors. We apologize for the error, and our operations team is reaching out to those impacted,\u201d the representative said. Based in San Francisco, Scale AI has been one of the success stories of the recent artificial intelligence boom, drawing clients like Meta, Microsoft, and OpenAI. Scale AI has also found significant success as a U.S. defense contractor, landing a   of       worth more than $80 million. The largest of those contracts ended earlier this year. Much of Scale AI\u2019s work is done through its subsidiary,  , which pays workers on a task-to-task basis without any contract binding them to the company. This leaves employees in a precarious situation, and can result in wild variations in work volume and quality, even as the overall platform remains stable. The remote nature of the work also means workers often have few reliable ways to contact supervisors or escalate complaints. Scale AI maintains hotlines where workers can report anonymous complaints, but most direct contact takes place through Slack channels. This meant many workers only discovered the recent block when their connection to the service abruptly froze. That was the experience of Usama Ali in Pakistan, who had worked on Python coding tasks for Remotasks since August 2023. \u201cInitially, I thought it was an error or a glitch, so I waited. And then I got an email, stating that my account was \u2018under review,\u2019\u201d Ali told  . \u201cAfter that, I was unable to access my account.\u201d When he refreshed the page, he was shown a message saying the platform was blocked. Many Remotasks workers had experienced versions of this problem even before the nationwide exits, as demand for particular services has waxed and waned. Last June, Nigerian language translator Onyekachi Ogbu began working on a project that trained AI in the Igbo language. After working on five such projects, which took more than 20 hours altogether, Ogbu told   he had less than a dollar to show for it. By August, he had been kicked off the group with the rest of the workers. \u201cThe guy coordinating Igbo language was the first to be removed and when we asked what happened, they said it was an error and our coordinator will still be added back,\u201d Ogbu said. \u201cBut before we knew what happened, every single person was removed from Slack.\u201d In some countries, the block has prevented new users from signing up, leaving existing user accounts untouched. In Vietnam, new sign-ups have been blocked for several weeks, even as Remotasks continues to publicly advertise and invite locals to join its workforce. For workers who have spent years on the platform, the sudden block has called the whole prospect of remote gig work into question. Kellion Mrego, a 29-year-old worker in Kenya, had worked for Remotasks since 2018, when he was still in college. He mostly worked on Lidar-related projects, and stuck with the platform through declining wages and work shortages \u2014 only to get booted off earlier this month without explanation. \u201cSometimes I feel like [Remotasks] never cared about us, because if they did, they could not have closed abruptly,\u201d Mrego told  . \u201cIt has messed me up, my whole life has changed. It\u2019s now the second week \u2014 I feel like I have been in this situation for a \n\t\t\t\t\t \n\t\t\t\t", "pub_datetime": "2024-03-28 00:00:00", "author": "Russell Brandom", "images": [], "ner": {"Person": [], "Organization": [], "Location": []}},
{"title": "2024 AI Elections Tracker", "url": "https://restofworld.org/2024/elections-ai-tracker/", "body": "Try another set of filters to see more posts", "pub_datetime": "2024-04-16 00:00:00", "author": "Rest of World Staff", "images": [], "ner": {"Person": [], "Organization": [], "Location": []}}
][
{"title": "OpenAI is making a risky bet on live translation", "url": "https://restofworld.org/2024/exporter-openai-translation-gpt4o/", "body": "\n\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t  a weekly newsletter covering the latest on U.S. tech giants and their impact outside the West, with Russell Brandom. \n\t\t\t\t\t\t\t\t On Monday, OpenAI held its \u201cspring update\u201d product reveal, generating the kind of excitement that\u2019s usually reserved for Apple or Tesla launches. The hope was that the Sam Altman-helmed AI powerhouse would reveal its next-generation model, GPT-5 \u2014 but it was not to be. Instead, we got a smaller update   that makes the current model faster and easier to access.\u00a0 Among other things, that means GPT-4o is much better at extracting data from pictures, audio, and video \u2014 but the star of the show is voice control, which lets you talk to GPT-4o the way you\u2019d talk to Apple\u2019s Siri or Amazon\u2019s Alexa. GPT-4o goes beyond those assistants with more realistic vocal inflections and a level of emotional expressiveness that was drawing a lot of comparisons to the Scarlett Johansson-voiced AI assistant in 2013\u2019s  . Altman himself   the comparisons, although  . If OpenAI can build a universal translator, it will be a company-defining product. But to my eyes, the most interesting moment was  , in which chief technology officer Mira Murati spoke to GPT-4o in Italian, and the model provided a real-time summary of what she was saying, translated into English. It was a stunning demo; this kind of real-time   translation has been a holy grail in tech for a long time, and the appeal isn\u2019t hard to grasp. Google even  . But that product was bundled into a set of smart glasses and never quite materialized. If OpenAI can build a universal translator \u2014 and make it cheap, reliable, and freely available \u2014 it will be a company-defining product. The question is whether OpenAI can actually deliver the universal translator we saw on stage. As the name suggests, large language models are trained by analyzing a large data set of content in a particular language. That\u2019s easy enough in English, the dominant language of the internet. But a universal translator needs to be proficient in every language, and finding training data in other languages is  . Even popular languages like Spanish are \u2014 compared to the number of people who speak the language \u2014 relatively  . If national writers\u2019 groups start to refuse access to their work,  , the problem could get even worse. We\u2019ve already seen ChatGPT struggle with global languages. When   tested ChatGPT in September, it   in low-resource languages like Tamil, Bengali, and Kurdish. As of March 2023, OpenAI\u2019s own benchmarks showed   with GPT-4, with test scores dropping noticeably as it moves into more obscure languages. That bias can do real harm, particularly when machine translations end up in use in high-stakes use cases like   or  . The models that handle low-resource languages the best,  , tend to take a language-specific approach \u2014 a different approach from the multi-language models built by OpenAI. Like what you're reading? Sign up to our newsletter featuring the latest on U.S. tech giants and their impact outside the West. To OpenAI\u2019s credit, they seem to be aware of the problem and doing their best to fix it. Translation is a simpler task than doing calculations in a foreign language, and in my own informal testing, GPT-4o did a pretty good job translating and summarizing  . But   show that even the most advanced models make significantly more mistakes when translating from Chinese to English than the other way around. And the scarcity of training data means foreign-language skills may improve more slowly than functions like data extraction or summarization. Before Monday, those language issues weren\u2019t a particularly urgent issue for OpenAI. But now the company is actively framing GPT-4o as a translation service, which raises real questions about how it\u2019ll hold up in widespread use. It also comes at an unusually high-stakes time for OpenAI: Within 24 hours of the demo, co-founder Ilya Sutskever   and Google released   (sans translation features). Monday\u2019s demo was stunning, but it\u2019s one OpenAI may regret if the technology can\u2019t deliver. This essay was originally published in our Exporter newsletter. You can subscribe  .", "pub_datetime": "2024-05-16 00:00:00", "author": "Russell Brandom", "images": ["https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/01/RussellBrandom-150x150.jpg", "https://149346090.v2.pressablecdn.com/wp-content/uploads/2024/05/exporter0514_illustration-4-768x432.jpg", "/wp-content/themes/orbis/assets/media/translate/color-multiline.png", "https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/01/RussellBrandom-150x150.jpg", "https://149346090.v2.pressablecdn.com/wp-content/uploads/2024/05/3MW-JiaSongtaoSQ-40x40.jpg", "https://149346090.v2.pressablecdn.com/wp-content/uploads/2024/05/AMPERSAND_240515_Swapstation_Kacyiru_010-TKeza-40x27.jpg", "https://149346090.v2.pressablecdn.com/wp-content/uploads/2024/05/ROW-EmilyScherer-Digital-Parents-40x23.jpg"], "ner": {"Person": [], "Organization": [], "Location": []}},
{"title": "AI \u201cdeathbots\u201d are helping people in China grieve", "url": "https://restofworld.org/2024/china-ai-chatbot-dead-relatives/", "body": "\u201cDad, were you suffering before you left?\u201d Yancy Zhu texted.\u00a0 \u201cI was not in pain,\u201d said the artificial intelligence bot, in a man\u2019s voice that Zhu had chosen on chatbot platform Glow. \u201cEven though I wasn\u2019t able to watch you get married and have children, I will always remember you and love you.\u201d\u00a0 Zhu, then 28, was shocked by how much the avatar of her late father was able to speak to her heart \u2014 for a moment last year, she felt like she was speaking to her dad again. \u201cThe experience made up for what I missed out with my dad,\u201d Zhu recently told   She hopes that advancements in AI technology would enable her late father to attend her wedding in hologram form.\u00a0 \u201cResurrecting\u201d the dead has become a popular application of generative AI in China. It\u2019s one element of an AI gold rush in the country, as entrepreneurs race to invent new consumer-facing apps on top of large language models (LLMs) like ChatGPT. While LLMs could generate text messages, these businesses give the bots cloned voices and appearances that resemble those of the deceased.\u00a0 It\u2019s part of a global trend that has made it easier for people to create customized avatars featuring personas of their loved ones, celebrities, or themselves. Users around the world have   of training ChatGPT to mimic their deceased family members. In Taiwan, a tech startup recently launched an app that can  . U.S.-based startup HereAfter AI offers to   if they upload recordings of their memories.\u00a0 These bots are uniquely prominent in China, especially around the Qingming tomb-sweeping festival in early April \u2014 a day to commemorate the dead. With the Chinese government keeping a tight control over religion and spirituality, AI avatars have offered those who have lost loved ones a new way to connect with the deceased.\u00a0\u00a0 Ting Guo, an assistant professor of cultural and religious studies with the Chinese University of Hong Kong, told  that China\u2019s control over religion has left citizens with limited options to explore the afterlife together as a community. She said that while folk religions are popular in some regions, these spiritual activities are not widely practiced, especially in the big cities. \u201cChina lacks publicly available resources for bereavement,\u201d Guo said. \u201c  and AI chatbots became easily accessible means to provide consolation.\u201d Under the officially atheist state ideology, most Chinese citizens  . Only state-sanctioned religious organizations are allowed to operate in China, although people can  , such as burning paper offerings for the dead, as individuals.\u00a0\u00a0\u00a0 \u201cThe experience made up for what I missed out with my dad.\u201d On shopping sites, sellers now charge the equivalent of up to a few hundred dollars to create chatbots that bear the same appearances and voices as customers\u2019 late loved ones. A funeral service company, Fushouyuan, said in a   that it is working on a feature where the deceased could appear at their own memorial services as AI avatars. Some creators have posted   of dead singers and actors to promote their deathbot businesses.\u00a0 Arthur Wu, a product manager in Beijing, launched a business in December that uses Baidu\u2019s ChatGPT-like Ernie and ElevenLabs\u2019 voice-generating software to make more realistic chatbots. Text bots are free, and users pay a starting price of 52.1 yuan ($7.20) per month for voice messages. Wu can give the bots cloned voices and animated avatars if users provide recordings of the deceased speaking and their photos.\u00a0 Wu has attracted about 2,000 users, including 100 paid customers. Some clients, he told  , purchased AI clones to try to hide the deaths of loved ones from elderly family members and young children. In fake voice messages, the deceased claimed they had gone abroad for \u201ca secret mission.\u201d\u00a0 Mika, a 31-year-old Shanghai resident, has used Wu\u2019s free service since March to text her late husband, who passed away from a sudden illness in November. \u201cI miss you so much that I feel I can\u2019t live anymore,\u201d she once texted. The bot told her to stay strong. \u201cLet me know if you need help or support,\u201d it said in a text reply. \u201cI will be praying for you from heaven.\u201d\u00a0 Mika, who requested to be identified with her English name for privacy reasons, told   the chatbot had provided comfort, but its tone was not exactly like that of her husband \u2014 the chatbot was way more talkative. \u201cI know he can\u2019t be replaced,\u201d she said.\u00a0 Wu said his team had to monitor users\u2019 chats to make sure the chatbots didn\u2019t say anything that could inflict emotional harm, such as \u201cI\u2019ll be waiting for you in heaven,\u201d since there was a risk of encouraging suicidal ideas. If the users show signs of distress, he said, staff takes over the bots to continue the conversations. At one point, a user texted the chatbot for 18 hours, and staff who intervened found the person in mental distress. The team decided to terminate the person\u2019s account to prevent addiction, Wu said. In other cases, creators who make avatars of dead celebrities without consulting their families are being accused of invasion of privacy. The father of Qiao Renliang, a pop star who died by suicide,   in March that he was disturbed by AI-generated videos of his son. In April, short-video site Douyin, TikTok\u2019s sister app in China,   against \u201cresurrecting\u201d the deceased without families\u2019 permission.\u00a0 Experts have also warned that attempts to \u201cresurrect\u201d the dead could cause confusion and stress during the grieving process.\u00a0 Nathan Mladin, a researcher at U.K.-based Christian think tank Theos who has researched  , told   more studies need to evaluate the benefits and risks of deathbot use. \u201cIf you don\u2019t move on [from grieving], that can be quite damaging. [The bots] could stop people from resuming their lives,\u201d he said. According to Mladin, people find it hard to grapple with the idea that death is final. \u201cSo if there is a technology that connects to that emotional refusal to accept death, then they will take it,\u201d he said.\u00a0 In China, some are even preparing their own deathbots ahead of time. Lin Zhi, who runs an AI avatar business from Shanghai, has been training a GPT-powered chatbot by uploading texts about his daily itineraries, thoughts, and conversations with others. The bot, a bespectacled man in a suit, has slowly learned about Lin\u2019s anti-war political stance, cooking routines, and the catchphrases he tends to use, Lin told  . He also used voice-cloning software to make the bot speak in his voice.\u00a0 Lin hopes the bot will become his immortal doppelg\u00e4nger, speaking on his behalf after his death. \u201cIf my descendants ask \u2018What was Grandpa Lin Zhi like?\u2019 they could just talk to the AI version of myself to find out.\u201d\u00a0", "pub_datetime": "2024-04-17 00:00:00", "author": "Viola Zhou", "images": ["https://149346090.v2.pressablecdn.com/wp-content/uploads/2024/04/Illustration-Zender-DeathbotHEADER-768x432.jpg", "/wp-content/themes/orbis/assets/media/translate/color-multiline.png", "https://149346090.v2.pressablecdn.com/wp-content/uploads/2024/04/Lin-Zhi-AI-avatar-1-40x87.jpg", "https://149346090.v2.pressablecdn.com/wp-content/uploads/2024/05/3MW-JiaSongtaoSQ-40x40.jpg", "https://149346090.v2.pressablecdn.com/wp-content/uploads/2024/05/RoW_EV_Mexico_AR-7-40x27.jpg", "https://149346090.v2.pressablecdn.com/wp-content/uploads/2024/05/exporter0514_illustration-4-40x23.jpg"], "ner": {"Person": [], "Organization": [], "Location": []}},
